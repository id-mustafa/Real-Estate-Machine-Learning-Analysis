{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install Packages"
      ],
      "metadata": {
        "id": "hSSh9iaisaHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supabase python-dotenv pandas tensorflow scikit-learn joblib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XtRBySbysWMi",
        "outputId": "086467db-7fb9-4efd-9014-2c19fd30f423",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supabase\n",
            "  Downloading supabase-2.15.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Collecting gotrue<3.0.0,>=2.11.0 (from supabase)\n",
            "  Downloading gotrue-2.12.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx<0.29,>=0.26 in /usr/local/lib/python3.11/dist-packages (from supabase) (0.28.1)\n",
            "Collecting postgrest<1.1,>0.19 (from supabase)\n",
            "  Downloading postgrest-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting realtime<2.5.0,>=2.4.0 (from supabase)\n",
            "  Downloading realtime-2.4.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting storage3<0.12,>=0.10 (from supabase)\n",
            "  Downloading storage3-0.11.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting supafunc<0.10,>=0.9 (from supabase)\n",
            "  Downloading supafunc-0.9.4-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.10 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.11.3)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.10.1)\n",
            "Collecting pytest-mock<4.0.0,>=3.14.0 (from gotrue<3.0.0,>=2.11.0->supabase)\n",
            "  Downloading pytest_mock-3.14.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.14.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Collecting deprecation<3.0.0,>=2.1.0 (from postgrest<1.1,>0.19->supabase)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /usr/local/lib/python3.11/dist-packages (from realtime<2.5.0,>=2.4.0->supabase) (3.11.15)\n",
            "Collecting websockets<15,>=11 (from realtime<2.5.0,>=2.4.0->supabase)\n",
            "  Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Collecting strenum<0.5.0,>=0.4.15 (from supafunc<0.10,>=0.9->supabase)\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (1.19.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.4.0)\n",
            "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.11/dist-packages (from pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (8.3.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (1.5.0)\n",
            "Downloading supabase-2.15.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading gotrue-2.12.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading postgrest-1.0.1-py3-none-any.whl (22 kB)\n",
            "Downloading realtime-2.4.2-py3-none-any.whl (22 kB)\n",
            "Downloading storage3-0.11.3-py3-none-any.whl (17 kB)\n",
            "Downloading supafunc-0.9.4-py3-none-any.whl (7.8 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pytest_mock-3.14.0-py3-none-any.whl (9.9 kB)\n",
            "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
            "Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: strenum, websockets, python-dotenv, deprecation, pytest-mock, realtime, supafunc, storage3, postgrest, gotrue, supabase\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "Successfully installed deprecation-2.1.0 gotrue-2.12.0 postgrest-1.0.1 pytest-mock-3.14.0 python-dotenv-1.1.0 realtime-2.4.2 storage3-0.11.3 strenum-0.4.15 supabase-2.15.0 supafunc-0.9.4 websockets-14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bring in data"
      ],
      "metadata": {
        "id": "9pnAwq4ZsxeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['SUPABASE_URL'] = 'https://lgcrogvgnqphznuwdopu.supabase.co'\n",
        "os.environ['SUPABASE_KEY'] = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImxnY3JvZ3ZnbnFwaHpudXdkb3B1Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDQ0MTQwMzcsImV4cCI6MjA1OTk5MDAzN30.2lozGgOq70UbrCm1_7Y1p38WbCqOMTjQ8Cs_ZSvNhSs'"
      ],
      "metadata": {
        "id": "v3HYrpXNs8Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import PsiKit Learn"
      ],
      "metadata": {
        "id": "RhPcDOg54oGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "Rz2Dq4tZ4xOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Database Setup"
      ],
      "metadata": {
        "id": "qIgz1FFwtlJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# db.py\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from supabase import create_client, Client\n",
        "import pandas as pd\n",
        "\n",
        "load_dotenv()\n",
        "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
        "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
        "\n",
        "def get_supabase_client() -> Client:\n",
        "    return create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "\n",
        "def fetch_housing_data() -> pd.DataFrame:\n",
        "    supabase = get_supabase_client()\n",
        "    response = supabase.table(\"Housing Data 2\").select(\"*\").execute()\n",
        "    data = response.data\n",
        "    df = pd.DataFrame(data)\n",
        "    return df"
      ],
      "metadata": {
        "id": "J0EFFUcjtrU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Database link"
      ],
      "metadata": {
        "id": "aZp22fF6uaC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from supabase import create_client, Client\n",
        "\n",
        "def fetch_housing_data() -> pd.DataFrame:\n",
        "    load_dotenv()\n",
        "    SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
        "    SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
        "\n",
        "    # Create the Supabase client\n",
        "    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "\n",
        "\n",
        "    response = supabase.table(\"Housing Data 2\").select(\"*\").execute()\n",
        "    data = response.data\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "LQUwr_JyucoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Script"
      ],
      "metadata": {
        "id": "qICHF1HUtuD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scripts/train_model.py\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "def train_model():\n",
        "\n",
        "    df = fetch_housing_data()\n",
        "\n",
        "\n",
        "    input_features = ['Price', '2022 Median Income', 'Bedroom', 'Bathroom', 'Area', 'Population']\n",
        "    target_features = ['Cost of Living', '2016 Crime Rate','WaterQualityVPV','AQI%Good','Unemployment']\n",
        "\n",
        "    X = df[input_features].fillna(df[input_features].median())\n",
        "    y = df[target_features].fillna(df[target_features].median())\n",
        "\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 5. Builds the  model\n",
        "    model = tf.keras.Sequential([\n",
        "       # tf.keras.layers.Dense(len(target_features), input_shape=(X_train.shape[1],))\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(len(target_features))\n",
        "    ])\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    #model.compile(optimizer='adam', loss='mean_squared_error') # Removing loss_weights\n",
        "\n",
        "    # 6. Train\n",
        "    model.fit(X_train, y_train, epochs=50, validation_split=0.1)\n",
        "\n",
        "    # 7. Evaluate\n",
        "    loss = model.evaluate(X_test, y_test)\n",
        "    print(\"Test loss:\", loss)\n",
        "\n",
        "    # Calculate R-squared and accuracy percentage\n",
        "    y_pred = model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(\"R-squared:\", r2)\n",
        "    accuracy_percentage = r2 * 100\n",
        "    print(f\"Accuracy: {accuracy_percentage:.2f}%\")\n",
        "\n",
        "    # 8. Save model & scaler\n",
        "    model.save(\"trained_model.h5\")\n",
        "\n",
        "    import joblib\n",
        "    joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_model()\n"
      ],
      "metadata": {
        "id": "xQ1fNRDXtxFG",
        "outputId": "626a2382-a538-4ecd-98e7-fbbd19b9cb40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1501386368.0000 - val_loss: 1525765888.0000\n",
            "Epoch 2/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1495553024.0000 - val_loss: 1525678720.0000\n",
            "Epoch 3/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1499069440.0000 - val_loss: 1525550720.0000\n",
            "Epoch 4/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1503577088.0000 - val_loss: 1525373440.0000\n",
            "Epoch 5/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1503083136.0000 - val_loss: 1525138048.0000\n",
            "Epoch 6/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1496751104.0000 - val_loss: 1524837632.0000\n",
            "Epoch 7/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1495925376.0000 - val_loss: 1524461312.0000\n",
            "Epoch 8/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1500807936.0000 - val_loss: 1524008704.0000\n",
            "Epoch 9/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1491139072.0000 - val_loss: 1523460480.0000\n",
            "Epoch 10/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1498781952.0000 - val_loss: 1522815488.0000\n",
            "Epoch 11/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1493836160.0000 - val_loss: 1522069248.0000\n",
            "Epoch 12/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1496146688.0000 - val_loss: 1521217024.0000\n",
            "Epoch 13/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1493050368.0000 - val_loss: 1520247040.0000\n",
            "Epoch 14/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1496702336.0000 - val_loss: 1519130112.0000\n",
            "Epoch 15/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1493479808.0000 - val_loss: 1517910656.0000\n",
            "Epoch 16/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1486133888.0000 - val_loss: 1516534400.0000\n",
            "Epoch 17/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1491039872.0000 - val_loss: 1515014016.0000\n",
            "Epoch 18/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1490333568.0000 - val_loss: 1513368192.0000\n",
            "Epoch 19/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1491044736.0000 - val_loss: 1511539456.0000\n",
            "Epoch 20/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1481008384.0000 - val_loss: 1509566464.0000\n",
            "Epoch 21/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1484828672.0000 - val_loss: 1507406208.0000\n",
            "Epoch 22/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1481460480.0000 - val_loss: 1505068160.0000\n",
            "Epoch 23/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1482598784.0000 - val_loss: 1502560896.0000\n",
            "Epoch 24/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1479350272.0000 - val_loss: 1499798656.0000\n",
            "Epoch 25/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1471342976.0000 - val_loss: 1496921728.0000\n",
            "Epoch 26/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1466827136.0000 - val_loss: 1493807360.0000\n",
            "Epoch 27/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1468901248.0000 - val_loss: 1490465664.0000\n",
            "Epoch 28/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1464346368.0000 - val_loss: 1486921600.0000\n",
            "Epoch 29/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1452577024.0000 - val_loss: 1483146496.0000\n",
            "Epoch 30/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1459435648.0000 - val_loss: 1479147648.0000\n",
            "Epoch 31/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1463854592.0000 - val_loss: 1474944640.0000\n",
            "Epoch 32/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1450450176.0000 - val_loss: 1470440192.0000\n",
            "Epoch 33/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1440944896.0000 - val_loss: 1465728768.0000\n",
            "Epoch 34/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1437152768.0000 - val_loss: 1460769024.0000\n",
            "Epoch 35/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1439071104.0000 - val_loss: 1455532032.0000\n",
            "Epoch 36/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1436313728.0000 - val_loss: 1450109184.0000\n",
            "Epoch 37/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1433260288.0000 - val_loss: 1444362240.0000\n",
            "Epoch 38/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1422296576.0000 - val_loss: 1438383488.0000\n",
            "Epoch 39/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1413735552.0000 - val_loss: 1432100608.0000\n",
            "Epoch 40/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1414717312.0000 - val_loss: 1425566976.0000\n",
            "Epoch 41/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1404179712.0000 - val_loss: 1418702080.0000\n",
            "Epoch 42/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1399918080.0000 - val_loss: 1411538048.0000\n",
            "Epoch 43/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1389798272.0000 - val_loss: 1404055808.0000\n",
            "Epoch 44/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1388445824.0000 - val_loss: 1396388480.0000\n",
            "Epoch 45/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1374200320.0000 - val_loss: 1388315392.0000\n",
            "Epoch 46/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1372854016.0000 - val_loss: 1379948800.0000\n",
            "Epoch 47/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1360794624.0000 - val_loss: 1371462400.0000\n",
            "Epoch 48/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1350137728.0000 - val_loss: 1362465664.0000\n",
            "Epoch 49/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1333215104.0000 - val_loss: 1353236224.0000\n",
            "Epoch 50/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1337612160.0000 - val_loss: 1343636736.0000\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1325524096.0000 \n",
            "Test loss: 1324349824.0\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "R-squared: -2388.906494140625\n",
            "Accuracy: -238890.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add-on"
      ],
      "metadata": {
        "id": "cNN2QR1GxsLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbdq2CSnxuVZ",
        "outputId": "c7dc5b62-ed05-44e9-bf5a-424f49139ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions on Model"
      ],
      "metadata": {
        "id": "_oDdWTFRxbLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "_odbxA3UW_gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# services/prediction.py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import joblib\n",
        "\n",
        "# Load the saved model\n",
        "model = tf.keras.models.load_model(\"trained_model.h5\")\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "\n",
        "def predict_house_metrics(user_input):\n",
        "    \"\"\"\n",
        "    user_input: dict or list that includes\n",
        "    [\n",
        "      Desired House Price,\n",
        "      Income,\n",
        "      # Beds,\n",
        "      # Baths,\n",
        "      Sq. ft,\n",
        "      Desired Population\n",
        "    ]\n",
        "    \"\"\"\n",
        "\n",
        "    data = np.array([[\n",
        "      user_input[\"house_price\"],\n",
        "      user_input[\"income\"],\n",
        "      user_input[\"beds\"],\n",
        "      user_input[\"baths\"],\n",
        "      user_input[\"sq_ft\"],\n",
        "      user_input[\"population\"]\n",
        "    ]])\n",
        "    # Scale\n",
        "    scaled_data = scaler.transform(data)\n",
        "    # Predict\n",
        "    prediction = model.predict(scaled_data)\n",
        "    return prediction.tolist()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7oPQav1xhn7",
        "outputId": "064cb36f-c5b9-4889-bd45-f83e6bde5138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find closest match"
      ],
      "metadata": {
        "id": "edo3YCq50_ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def find_closest_matches(user_input, df, scaler,num_matches=5):\n",
        "    \"\"\"\n",
        "    Given a user_input dictionary, a DataFrame df with the housing records,\n",
        "    and a scaler used for the training data, this function finds the record\n",
        "    in df that is closest to the user's desired features.\n",
        "\n",
        "    Parameters:\n",
        "      - user_input: dict with keys \"house_price\", \"income\", \"beds\",\n",
        "                    \"baths\", \"sq_ft\", \"population\"\n",
        "      - df: DataFrame of housing records containing at least the following columns:\n",
        "            ['ListedPrice', 'MeanIncome', 'Bedroom', 'Bathroom', 'Area', '2022 Population']\n",
        "            plus location columns like \"State\", \"City\".\n",
        "      - scaler: A StandardScaler fitted on the training data.\n",
        "\n",
        "    Returns:\n",
        "      - closest_match: A Pandas Series that represents the record closest to the input.\n",
        "    \"\"\"\n",
        "\n",
        "    input_features = ['Price', '2022 Median Income', 'Bedroom', 'Bathroom', 'Area', 'Population']\n",
        "\n",
        "    # Construct the user vector from the dictionary\n",
        "    user_vector = np.array([[user_input[\"house_price\"],\n",
        "                              user_input[\"income\"],\n",
        "                              user_input[\"beds\"],\n",
        "                              user_input[\"baths\"],\n",
        "                              user_input[\"sq_ft\"],\n",
        "                              user_input[\"population\"]]])\n",
        "\n",
        "\n",
        "    user_vector_scaled = scaler.transform(user_vector)\n",
        "\n",
        "\n",
        "    data_features = df[input_features].fillna(df[input_features].median())\n",
        "\n",
        "\n",
        "    data_features_scaled = scaler.transform(data_features)\n",
        "\n",
        "\n",
        "    distances = np.linalg.norm(data_features_scaled - user_vector_scaled, axis=1)\n",
        "\n",
        "    closest_indices = np.argsort(distances)[:num_matches]\n",
        "    closest_matches = df.iloc[closest_indices]\n",
        "    #idx = np.argmin(distances)\n",
        "    #closest_match = df.iloc[idx]\n",
        "\n",
        "    return closest_matches\n"
      ],
      "metadata": {
        "id": "A3CCjRWR1C9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "User Input and Output"
      ],
      "metadata": {
        "id": "H2VLUTZW1FIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = fetch_housing_data()\n",
        "print(\"Data loaded:\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "house_price = input(\"Enter your desired house price (or press Enter to skip): \")\n",
        "income = input(\"Enter your income (or press Enter to skip): \")\n",
        "beds = input(\"Enter number of beds (or press Enter to skip): \")\n",
        "baths = input(\"Enter number of baths (or press Enter to skip): \")\n",
        "sq_ft = input(\"Enter square footage (or press Enter to skip): \")\n",
        "population = input(\"Enter desired population (or press Enter to skip): \")\n",
        "\n",
        "\n",
        "\n",
        "user_input = {}\n",
        "for feature, value in zip(\n",
        "    [\"house_price\", \"income\", \"beds\", \"baths\", \"sq_ft\", \"population\"],\n",
        "    [house_price, income, beds, baths, sq_ft, population],\n",
        "):\n",
        "    if value == \"\":\n",
        "        user_input[feature] = df[\n",
        "            {\n",
        "                \"house_price\": \"Price\",\n",
        "                \"income\": \"2022 Median Income\",\n",
        "                \"beds\": \"Bedroom\",\n",
        "                \"baths\": \"Bathroom\",\n",
        "                \"sq_ft\": \"Area\",\n",
        "                \"population\": \"Population\",\n",
        "            }[feature]\n",
        "        ].median()\n",
        "    else:\n",
        "        user_input[feature] = float(value)\n",
        "\n",
        "# 2. Get model prediction\n",
        "prediction = predict_house_metrics(user_input)\n",
        "print(\"Prediction outputs (model's numerical predictions):\", prediction)\n",
        "\n",
        "\n",
        "df = fetch_housing_data()\n",
        "print(\"Full dataset loaded (first 5 rows):\")\n",
        "print(df.head())\n",
        "\n",
        "# 4. Find the closest matching record\n",
        "closest_matches = find_closest_matches(user_input, df, scaler)\n",
        "\n",
        "\n",
        "print(\"\\nClosest Matching House Record:\")\n",
        "for i in range(len(closest_matches)):\n",
        "    match = closest_matches.iloc[i]\n",
        "    print(f\"\\nMatch {i + 1}:\")\n",
        "print(\"State:\", closest_matches.get(\"State\", \"N/A\"))\n",
        "print(\"City:\", closest_matches.get(\"City\", \"N/A\"))\n",
        "print(\"Price:\", closest_matches.get(\"Price\", \"N/A\"))\n",
        "print(\"2022 Median Income:\", closest_matches.get(\"2022 Median Income\", \"N/A\"))\n",
        "print(\"Bedrooms:\", closest_matches.get(\"Bedroom\", \"N/A\"))\n",
        "print(\"Bathrooms:\", closest_matches.get(\"Bathroom\", \"N/A\"))\n",
        "print(\"Area:\", closest_matches.get(\"Area\", \"N/A\"))\n",
        "print(\"Population:\", closest_matches.get(\"Population\", \"N/A\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD6g5KIgz5VA",
        "outputId": "b9d1d916-e9de-4d31-f051-115d714bddb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded:\n",
            "  State          City  Bedroom  Bathroom  Area  LotArea   Price  Temperature  \\\n",
            "0    ct  new haven,ct        3         1   901     0.08  159900            1   \n",
            "1    ct  new haven,ct        8         3  3008     0.09  419999            1   \n",
            "2    ct  new haven,ct        6         2  1677     0.07  225000            1   \n",
            "3    ct  new haven,ct        6         4  2099     0.07  175000            1   \n",
            "4    ct  new haven,ct        6         3  2969     0.10  274900            1   \n",
            "\n",
            "   2016 Crime Rate  Unemployment  AQI%Good  WaterQualityVPV  Cost of Living  \\\n",
            "0            0.027           4.5     84.99                3        88957.67   \n",
            "1            0.027           4.5     84.99                3        88957.67   \n",
            "2            0.027           4.5     84.99                3        88957.67   \n",
            "3            0.027           4.5     84.99                3        88957.67   \n",
            "4            0.027           4.5     84.99                3        88957.67   \n",
            "\n",
            "   2022 Median Income  Population  \n",
            "0            92875.39      138915  \n",
            "1            92875.39      138915  \n",
            "2            92875.39      138915  \n",
            "3            92875.39      138915  \n",
            "4            92875.39      138915  \n",
            "Enter your desired house price (or press Enter to skip): 400000\n",
            "Enter your income (or press Enter to skip): 250000\n",
            "Enter number of beds (or press Enter to skip): 4\n",
            "Enter number of baths (or press Enter to skip): 2.5\n",
            "Enter square footage (or press Enter to skip): \n",
            "Enter desired population (or press Enter to skip): \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction outputs (model's numerical predictions): [[8.138130187988281, 0.08783741295337677, 1.8600270748138428, 1.9495023488998413, 0.539458155632019]]\n",
            "Full dataset loaded (first 5 rows):\n",
            "  State         City  Bedroom  Bathroom  Area  LotArea   Price  Temperature  \\\n",
            "0    ct  stamford,ct        4         3  2448     1.00  775000            1   \n",
            "1    ct  stamford,ct        4         2  1768     0.11  325000            1   \n",
            "2    ct  stamford,ct        3         1  1290     0.26  325000            1   \n",
            "3    ct   norwalk,ct        3         2  1456     0.11  409000            1   \n",
            "4    ct  stamford,ct        3         2  1534     0.11  539000            1   \n",
            "\n",
            "   2016 Crime Rate  Unemployment  AQI%Good  WaterQualityVPV  Cost of Living  \\\n",
            "0            0.016          4.32     84.99                8       104217.94   \n",
            "1            0.016          4.32     84.99                8       104217.94   \n",
            "2            0.016          4.32     84.99                8       104217.94   \n",
            "3            0.016          4.32     84.99               19       104217.94   \n",
            "4            0.016          4.32     84.99                8       104217.94   \n",
            "\n",
            "   2022 Median Income  Population  \n",
            "0           121937.65      136188  \n",
            "1           121937.65      136188  \n",
            "2           121937.65      136188  \n",
            "3           121937.65       91401  \n",
            "4           121937.65      136188  \n",
            "\n",
            "Closest Matching House Record:\n",
            "\n",
            "Match 1:\n",
            "\n",
            "Match 2:\n",
            "\n",
            "Match 3:\n",
            "\n",
            "Match 4:\n",
            "\n",
            "Match 5:\n",
            "State: 116    nj\n",
            "692    nj\n",
            "505    nj\n",
            "702    nj\n",
            "111    nj\n",
            "Name: State, dtype: object\n",
            "City: 116       boonton,nj\n",
            "692         dover,nj\n",
            "505    morristown,nj\n",
            "702         dover,nj\n",
            "111       boonton,nj\n",
            "Name: City, dtype: object\n",
            "Price: 116    595000\n",
            "692    475000\n",
            "505    649000\n",
            "702    659000\n",
            "111    486000\n",
            "Name: Price, dtype: int64\n",
            "2022 Median Income: 116    145432.45\n",
            "692    145432.45\n",
            "505    145432.45\n",
            "702    145432.45\n",
            "111    145432.45\n",
            "Name: 2022 Median Income, dtype: float64\n",
            "Bedrooms: 116    4\n",
            "692    5\n",
            "505    3\n",
            "702    3\n",
            "111    3\n",
            "Name: Bedroom, dtype: int64\n",
            "Bathrooms: 116    3\n",
            "692    2\n",
            "505    3\n",
            "702    3\n",
            "111    3\n",
            "Name: Bathroom, dtype: int64\n",
            "Area: 116    2086\n",
            "692    1920\n",
            "505    1838\n",
            "702    2200\n",
            "111    2080\n",
            "Name: Area, dtype: int64\n",
            "Population: 116     8815\n",
            "692    18422\n",
            "505    20339\n",
            "702    18422\n",
            "111     8815\n",
            "Name: Population, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Model"
      ],
      "metadata": {
        "id": "Jtd9pPrH6VMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from supabase import create_client, Client\n",
        "\n",
        "def fetch_housing_data() -> pd.DataFrame:\n",
        "    load_dotenv()\n",
        "    SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
        "    SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
        "    client: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "    response = client.table(\"Housing Data 2\").select(\"*\").execute()\n",
        "    data = response.data\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "def train_model():\n",
        "\n",
        "    df = fetch_housing_data()\n",
        "\n",
        "\n",
        "    input_features = ['Price', '2022 Median Income', 'Bedroom', 'Bathroom', 'Area', 'Population']\n",
        "    target_features = ['Cost of Living', '2016 Crime Rate','WaterQualityVPV','AQI%Good','Unemployment']\n",
        "\n",
        "    X = df[input_features].fillna(df[input_features].median())\n",
        "    y = df[target_features].fillna(df[target_features].median())\n",
        "\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "    y_scaler = StandardScaler()\n",
        "    y_scaled = y_scaler.fit_transform(y)\n",
        "\n",
        "    # 4. Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 5. Build model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(len(target_features), input_shape=(X_train.shape[1],))\n",
        "    ])\n",
        "\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # 6. Train\n",
        "    model.fit(X_train, y_train, epochs=50, validation_split=0.1)\n",
        "\n",
        "    # 7. Evaluate\n",
        "    loss = model.evaluate(X_test, y_test)\n",
        "    print(\"Test loss:\", loss)\n",
        "\n",
        "    # 8. Save model & scaler if needed\n",
        "    model.save(\"trained_model.h5\")\n",
        "\n",
        "    import joblib\n",
        "    joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6748613a-b4ba-4b77-d2b3-70c6c4132e01",
        "id": "UohCPn7e6Snb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1861447808.0000 - val_loss: 1835735424.0000\n",
            "Epoch 2/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1865167744.0000 - val_loss: 1835734656.0000\n",
            "Epoch 3/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1829296256.0000 - val_loss: 1835733760.0000\n",
            "Epoch 4/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1852225408.0000 - val_loss: 1835732992.0000\n",
            "Epoch 5/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1875286400.0000 - val_loss: 1835732224.0000\n",
            "Epoch 6/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1820303744.0000 - val_loss: 1835731328.0000\n",
            "Epoch 7/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1884602368.0000 - val_loss: 1835730560.0000\n",
            "Epoch 8/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1849080064.0000 - val_loss: 1835729664.0000\n",
            "Epoch 9/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1821059712.0000 - val_loss: 1835728896.0000\n",
            "Epoch 10/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1862068736.0000 - val_loss: 1835728128.0000\n",
            "Epoch 11/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1869347840.0000 - val_loss: 1835727232.0000\n",
            "Epoch 12/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1847382272.0000 - val_loss: 1835726464.0000\n",
            "Epoch 13/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1835957632.0000 - val_loss: 1835725568.0000\n",
            "Epoch 14/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1832893696.0000 - val_loss: 1835724800.0000\n",
            "Epoch 15/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1841390592.0000 - val_loss: 1835724032.0000\n",
            "Epoch 16/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1832179584.0000 - val_loss: 1835723136.0000\n",
            "Epoch 17/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1812236544.0000 - val_loss: 1835722368.0000\n",
            "Epoch 18/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1835789312.0000 - val_loss: 1835721472.0000\n",
            "Epoch 19/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1806930688.0000 - val_loss: 1835720704.0000\n",
            "Epoch 20/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1843147520.0000 - val_loss: 1835719936.0000\n",
            "Epoch 21/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1850526976.0000 - val_loss: 1835719040.0000\n",
            "Epoch 22/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1851409792.0000 - val_loss: 1835718272.0000\n",
            "Epoch 23/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1802253184.0000 - val_loss: 1835717376.0000\n",
            "Epoch 24/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1868482304.0000 - val_loss: 1835716608.0000\n",
            "Epoch 25/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1873985152.0000 - val_loss: 1835715840.0000\n",
            "Epoch 26/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1888710272.0000 - val_loss: 1835714944.0000\n",
            "Epoch 27/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1847975936.0000 - val_loss: 1835714176.0000\n",
            "Epoch 28/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1866171520.0000 - val_loss: 1835713280.0000\n",
            "Epoch 29/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1843849856.0000 - val_loss: 1835712512.0000\n",
            "Epoch 30/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1845725184.0000 - val_loss: 1835711744.0000\n",
            "Epoch 31/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1854430208.0000 - val_loss: 1835710848.0000\n",
            "Epoch 32/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1848002048.0000 - val_loss: 1835710208.0000\n",
            "Epoch 33/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1803516544.0000 - val_loss: 1835709184.0000\n",
            "Epoch 34/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1807081088.0000 - val_loss: 1835708416.0000\n",
            "Epoch 35/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1829212800.0000 - val_loss: 1835707648.0000\n",
            "Epoch 36/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1867025536.0000 - val_loss: 1835706752.0000\n",
            "Epoch 37/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1826282240.0000 - val_loss: 1835705984.0000\n",
            "Epoch 38/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1859233664.0000 - val_loss: 1835705088.0000\n",
            "Epoch 39/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1840408192.0000 - val_loss: 1835704320.0000\n",
            "Epoch 40/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1835647232.0000 - val_loss: 1835703552.0000\n",
            "Epoch 41/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1846809728.0000 - val_loss: 1835702912.0000\n",
            "Epoch 42/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1853499392.0000 - val_loss: 1835701888.0000\n",
            "Epoch 43/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1847811840.0000 - val_loss: 1835701248.0000\n",
            "Epoch 44/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1886869120.0000 - val_loss: 1835700480.0000\n",
            "Epoch 45/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1818294656.0000 - val_loss: 1835699456.0000\n",
            "Epoch 46/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1836768000.0000 - val_loss: 1835698560.0000\n",
            "Epoch 47/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1814447872.0000 - val_loss: 1835697792.0000\n",
            "Epoch 48/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1861653760.0000 - val_loss: 1835696896.0000\n",
            "Epoch 49/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1844552192.0000 - val_loss: 1835696384.0000\n",
            "Epoch 50/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1858240512.0000 - val_loss: 1835695360.0000\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1814500096.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1806034688.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}