{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: DOWNLOADING DATA FROM SUPABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1000 rows so far...\n",
      "Downloaded 2000 rows so far...\n",
      "Downloaded 3000 rows so far...\n",
      "Downloaded 4000 rows so far...\n",
      "Downloaded 5000 rows so far...\n",
      "Downloaded 6000 rows so far...\n",
      "Downloaded 7000 rows so far...\n",
      "Downloaded 8000 rows so far...\n",
      "Downloaded 9000 rows so far...\n",
      "Downloaded 10000 rows so far...\n",
      "Downloaded 11000 rows so far...\n",
      "Downloaded 12000 rows so far...\n",
      "Downloaded 13000 rows so far...\n",
      "Downloaded 14000 rows so far...\n",
      "Downloaded 15000 rows so far...\n",
      "Downloaded 16000 rows so far...\n",
      "Downloaded 17000 rows so far...\n",
      "Downloaded 18000 rows so far...\n",
      "Downloaded 19000 rows so far...\n",
      "Downloaded 20000 rows so far...\n",
      "Downloaded 21000 rows so far...\n",
      "Downloaded 22000 rows so far...\n",
      "Downloaded 23000 rows so far...\n",
      "Downloaded 24000 rows so far...\n",
      "Downloaded 25000 rows so far...\n",
      "Downloaded 26000 rows so far...\n",
      "Downloaded 27000 rows so far...\n",
      "Downloaded 28000 rows so far...\n",
      "Downloaded 29000 rows so far...\n",
      "Downloaded 30000 rows so far...\n",
      "Downloaded 31000 rows so far...\n",
      "Downloaded 32000 rows so far...\n",
      "Downloaded 33000 rows so far...\n",
      "Downloaded 34000 rows so far...\n",
      "Downloaded 35000 rows so far...\n",
      "Downloaded 36000 rows so far...\n",
      "Downloaded 37000 rows so far...\n",
      "Downloaded 38000 rows so far...\n",
      "Downloaded 39000 rows so far...\n",
      "Downloaded 40000 rows so far...\n",
      "Downloaded 41000 rows so far...\n",
      "Downloaded 42000 rows so far...\n",
      "Downloaded 43000 rows so far...\n",
      "Downloaded 44000 rows so far...\n",
      "Downloaded 45000 rows so far...\n",
      "Downloaded 46000 rows so far...\n",
      "Downloaded 47000 rows so far...\n",
      "Downloaded 48000 rows so far...\n",
      "Downloaded 49000 rows so far...\n",
      "Downloaded 50000 rows so far...\n",
      "Downloaded 51000 rows so far...\n",
      "Downloaded 52000 rows so far...\n",
      "Downloaded 53000 rows so far...\n",
      "Downloaded 54000 rows so far...\n",
      "Downloaded 55000 rows so far...\n",
      "Downloaded 56000 rows so far...\n",
      "Downloaded 57000 rows so far...\n",
      "Downloaded 58000 rows so far...\n",
      "Downloaded 59000 rows so far...\n",
      "Downloaded 60000 rows so far...\n",
      "Downloaded 61000 rows so far...\n",
      "Downloaded 62000 rows so far...\n",
      "Downloaded 63000 rows so far...\n",
      "Downloaded 64000 rows so far...\n",
      "Downloaded 65000 rows so far...\n",
      "Downloaded 66000 rows so far...\n",
      "Downloaded 67000 rows so far...\n",
      "Downloaded 68000 rows so far...\n",
      "Downloaded 69000 rows so far...\n",
      "Downloaded 70000 rows so far...\n",
      "Downloaded 71000 rows so far...\n",
      "Downloaded 72000 rows so far...\n",
      "Downloaded 73000 rows so far...\n",
      "Downloaded 74000 rows so far...\n",
      "Downloaded 75000 rows so far...\n",
      "Downloaded 76000 rows so far...\n",
      "Downloaded 77000 rows so far...\n",
      "Downloaded 78000 rows so far...\n",
      "Downloaded 79000 rows so far...\n",
      "Downloaded 80000 rows so far...\n",
      "Downloaded 81000 rows so far...\n",
      "Downloaded 82000 rows so far...\n",
      "Downloaded 83000 rows so far...\n",
      "Downloaded 84000 rows so far...\n",
      "Downloaded 85000 rows so far...\n",
      "Downloaded 86000 rows so far...\n",
      "Downloaded 87000 rows so far...\n",
      "Downloaded 88000 rows so far...\n",
      "Downloaded 89000 rows so far...\n",
      "Downloaded 90000 rows so far...\n",
      "Downloaded 91000 rows so far...\n",
      "Downloaded 92000 rows so far...\n",
      "Downloaded 93000 rows so far...\n",
      "Downloaded 94000 rows so far...\n",
      "Downloaded 95000 rows so far...\n",
      "Downloaded 96000 rows so far...\n",
      "Downloaded 97000 rows so far...\n",
      "Downloaded 98000 rows so far...\n",
      "Downloaded 99000 rows so far...\n",
      "Downloaded 100000 rows so far...\n",
      "Downloaded 101000 rows so far...\n",
      "Downloaded 102000 rows so far...\n",
      "Downloaded 103000 rows so far...\n",
      "Downloaded 104000 rows so far...\n",
      "Downloaded 105000 rows so far...\n",
      "Downloaded 106000 rows so far...\n",
      "Downloaded 107000 rows so far...\n",
      "Downloaded 108000 rows so far...\n",
      "Downloaded 109000 rows so far...\n",
      "Downloaded 110000 rows so far...\n",
      "Downloaded 111000 rows so far...\n",
      "Downloaded 112000 rows so far...\n",
      "Downloaded 113000 rows so far...\n",
      "Downloaded 114000 rows so far...\n",
      "Downloaded 115000 rows so far...\n",
      "Downloaded 116000 rows so far...\n",
      "Downloaded 117000 rows so far...\n",
      "Downloaded 118000 rows so far...\n",
      "Downloaded 119000 rows so far...\n",
      "Downloaded 120000 rows so far...\n",
      "Downloaded 121000 rows so far...\n",
      "Downloaded 122000 rows so far...\n",
      "Downloaded 123000 rows so far...\n",
      "Downloaded 124000 rows so far...\n",
      "Downloaded 125000 rows so far...\n",
      "Downloaded 126000 rows so far...\n",
      "Downloaded 127000 rows so far...\n",
      "Downloaded 128000 rows so far...\n",
      "Downloaded 129000 rows so far...\n",
      "Downloaded 130000 rows so far...\n",
      "Downloaded 131000 rows so far...\n",
      "Downloaded 132000 rows so far...\n",
      "Downloaded 133000 rows so far...\n",
      "Downloaded 134000 rows so far...\n",
      "Downloaded 135000 rows so far...\n",
      "Downloaded 136000 rows so far...\n",
      "Downloaded 137000 rows so far...\n",
      "Downloaded 138000 rows so far...\n",
      "Downloaded 139000 rows so far...\n",
      "Downloaded 140000 rows so far...\n",
      "Downloaded 141000 rows so far...\n",
      "Downloaded 142000 rows so far...\n",
      "Downloaded 143000 rows so far...\n",
      "Downloaded 144000 rows so far...\n",
      "Downloaded 145000 rows so far...\n",
      "Downloaded 146000 rows so far...\n",
      "Downloaded 147000 rows so far...\n",
      "Downloaded 148000 rows so far...\n",
      "Downloaded 149000 rows so far...\n",
      "Downloaded 150000 rows so far...\n",
      "Downloaded 151000 rows so far...\n",
      "Downloaded 152000 rows so far...\n",
      "Downloaded 153000 rows so far...\n",
      "Downloaded 154000 rows so far...\n",
      "Downloaded 155000 rows so far...\n",
      "Downloaded 156000 rows so far...\n",
      "Downloaded 157000 rows so far...\n",
      "Downloaded 158000 rows so far...\n",
      "Downloaded 159000 rows so far...\n",
      "Downloaded 160000 rows so far...\n",
      "Downloaded 161000 rows so far...\n",
      "Downloaded 162000 rows so far...\n",
      "Downloaded 163000 rows so far...\n",
      "Downloaded 164000 rows so far...\n",
      "Downloaded 165000 rows so far...\n",
      "Downloaded 166000 rows so far...\n",
      "Downloaded 167000 rows so far...\n",
      "Downloaded 168000 rows so far...\n",
      "Downloaded 169000 rows so far...\n",
      "Downloaded 170000 rows so far...\n",
      "Downloaded 171000 rows so far...\n",
      "Downloaded 172000 rows so far...\n",
      "Downloaded 173000 rows so far...\n",
      "Downloaded 174000 rows so far...\n",
      "Downloaded 175000 rows so far...\n",
      "Downloaded 176000 rows so far...\n",
      "Downloaded 177000 rows so far...\n",
      "Downloaded 178000 rows so far...\n",
      "Downloaded 179000 rows so far...\n",
      "Downloaded 180000 rows so far...\n",
      "Downloaded 181000 rows so far...\n",
      "Downloaded 182000 rows so far...\n",
      "Downloaded 183000 rows so far...\n",
      "Downloaded 184000 rows so far...\n",
      "Downloaded 185000 rows so far...\n",
      "Downloaded 186000 rows so far...\n",
      "Downloaded 187000 rows so far...\n",
      "Downloaded 188000 rows so far...\n",
      "Downloaded 189000 rows so far...\n",
      "Downloaded 190000 rows so far...\n",
      "Downloaded 191000 rows so far...\n",
      "Downloaded 192000 rows so far...\n",
      "Downloaded 193000 rows so far...\n",
      "Downloaded 194000 rows so far...\n",
      "Downloaded 195000 rows so far...\n",
      "Downloaded 196000 rows so far...\n",
      "Downloaded 197000 rows so far...\n",
      "Downloaded 198000 rows so far...\n",
      "Downloaded 199000 rows so far...\n",
      "Downloaded 200000 rows so far...\n",
      "Downloaded 201000 rows so far...\n",
      "Downloaded 202000 rows so far...\n",
      "Downloaded 203000 rows so far...\n",
      "Downloaded 204000 rows so far...\n",
      "Downloaded 205000 rows so far...\n",
      "Downloaded 206000 rows so far...\n",
      "Downloaded 207000 rows so far...\n",
      "Downloaded 208000 rows so far...\n",
      "Downloaded 209000 rows so far...\n",
      "Downloaded 210000 rows so far...\n",
      "Downloaded 211000 rows so far...\n",
      "Downloaded 212000 rows so far...\n",
      "Downloaded 213000 rows so far...\n",
      "Downloaded 214000 rows so far...\n",
      "Downloaded 215000 rows so far...\n",
      "Downloaded 216000 rows so far...\n",
      "Downloaded 217000 rows so far...\n",
      "Downloaded 218000 rows so far...\n",
      "Downloaded 219000 rows so far...\n",
      "Downloaded 220000 rows so far...\n",
      "Downloaded 221000 rows so far...\n",
      "Downloaded 222000 rows so far...\n",
      "Downloaded 223000 rows so far...\n",
      "Downloaded 224000 rows so far...\n",
      "Downloaded 225000 rows so far...\n",
      "Downloaded 226000 rows so far...\n",
      "Downloaded 227000 rows so far...\n",
      "Downloaded 228000 rows so far...\n",
      "Downloaded 229000 rows so far...\n",
      "Downloaded 230000 rows so far...\n",
      "Downloaded 231000 rows so far...\n",
      "Downloaded 232000 rows so far...\n",
      "Downloaded 233000 rows so far...\n",
      "Downloaded 234000 rows so far...\n",
      "Downloaded 235000 rows so far...\n",
      "Downloaded 236000 rows so far...\n",
      "Downloaded 237000 rows so far...\n",
      "Downloaded 238000 rows so far...\n",
      "Downloaded 239000 rows so far...\n",
      "Downloaded 240000 rows so far...\n",
      "Downloaded 241000 rows so far...\n",
      "Downloaded 242000 rows so far...\n",
      "Downloaded 243000 rows so far...\n",
      "Downloaded 244000 rows so far...\n",
      "Downloaded 245000 rows so far...\n",
      "Downloaded 246000 rows so far...\n",
      "Downloaded 247000 rows so far...\n",
      "Downloaded 248000 rows so far...\n",
      "Downloaded 249000 rows so far...\n",
      "Downloaded 250000 rows so far...\n",
      "Downloaded 251000 rows so far...\n",
      "Downloaded 252000 rows so far...\n",
      "Downloaded 253000 rows so far...\n",
      "Downloaded 254000 rows so far...\n",
      "Downloaded 255000 rows so far...\n",
      "Downloaded 256000 rows so far...\n",
      "Downloaded 257000 rows so far...\n",
      "Downloaded 258000 rows so far...\n",
      "Downloaded 259000 rows so far...\n",
      "Downloaded 260000 rows so far...\n",
      "Downloaded 261000 rows so far...\n",
      "Downloaded 262000 rows so far...\n",
      "Downloaded 263000 rows so far...\n",
      "Downloaded 264000 rows so far...\n",
      "Downloaded 265000 rows so far...\n",
      "Downloaded 266000 rows so far...\n",
      "Downloaded 267000 rows so far...\n",
      "Downloaded 268000 rows so far...\n",
      "Downloaded 269000 rows so far...\n",
      "Downloaded 270000 rows so far...\n",
      "Downloaded 271000 rows so far...\n",
      "Downloaded 272000 rows so far...\n",
      "Downloaded 273000 rows so far...\n",
      "Downloaded 274000 rows so far...\n",
      "Downloaded 275000 rows so far...\n",
      "Downloaded 276000 rows so far...\n",
      "Downloaded 277000 rows so far...\n",
      "Downloaded 278000 rows so far...\n",
      "Downloaded 279000 rows so far...\n",
      "Downloaded 280000 rows so far...\n",
      "Downloaded 281000 rows so far...\n",
      "Downloaded 282000 rows so far...\n",
      "Downloaded 283000 rows so far...\n",
      "Downloaded 284000 rows so far...\n",
      "Downloaded 285000 rows so far...\n",
      "Downloaded 286000 rows so far...\n",
      "Downloaded 287000 rows so far...\n",
      "Downloaded 288000 rows so far...\n",
      "Downloaded 289000 rows so far...\n",
      "Downloaded 290000 rows so far...\n",
      "Downloaded 291000 rows so far...\n",
      "Downloaded 292000 rows so far...\n",
      "Downloaded 293000 rows so far...\n",
      "Downloaded 294000 rows so far...\n",
      "Downloaded 295000 rows so far...\n",
      "Downloaded 296000 rows so far...\n",
      "Downloaded 297000 rows so far...\n",
      "Downloaded 298000 rows so far...\n",
      "Downloaded 299000 rows so far...\n",
      "Downloaded 300000 rows so far...\n",
      "Downloaded 301000 rows so far...\n",
      "Downloaded 302000 rows so far...\n",
      "Downloaded 303000 rows so far...\n",
      "Downloaded 304000 rows so far...\n",
      "Downloaded 305000 rows so far...\n",
      "Downloaded 306000 rows so far...\n",
      "Downloaded 307000 rows so far...\n",
      "Downloaded 308000 rows so far...\n",
      "Downloaded 309000 rows so far...\n",
      "Downloaded 310000 rows so far...\n",
      "Downloaded 311000 rows so far...\n",
      "Downloaded 312000 rows so far...\n",
      "Downloaded 313000 rows so far...\n",
      "Downloaded 314000 rows so far...\n",
      "Downloaded 315000 rows so far...\n",
      "Downloaded 316000 rows so far...\n",
      "Downloaded 317000 rows so far...\n",
      "Downloaded 318000 rows so far...\n",
      "Downloaded 319000 rows so far...\n",
      "Downloaded 320000 rows so far...\n",
      "Downloaded 321000 rows so far...\n",
      "Downloaded 322000 rows so far...\n",
      "Downloaded 323000 rows so far...\n",
      "Downloaded 324000 rows so far...\n",
      "Downloaded 325000 rows so far...\n",
      "Downloaded 326000 rows so far...\n",
      "Downloaded 327000 rows so far...\n",
      "Downloaded 328000 rows so far...\n",
      "Downloaded 329000 rows so far...\n",
      "Downloaded 330000 rows so far...\n",
      "Downloaded 331000 rows so far...\n",
      "Downloaded 332000 rows so far...\n",
      "Downloaded 333000 rows so far...\n",
      "Downloaded 334000 rows so far...\n",
      "Downloaded 335000 rows so far...\n",
      "Downloaded 336000 rows so far...\n",
      "Downloaded 337000 rows so far...\n",
      "Downloaded 338000 rows so far...\n",
      "Downloaded 339000 rows so far...\n",
      "Downloaded 340000 rows so far...\n",
      "Downloaded 341000 rows so far...\n",
      "Downloaded 342000 rows so far...\n",
      "Downloaded 343000 rows so far...\n",
      "Downloaded 344000 rows so far...\n",
      "Downloaded 345000 rows so far...\n",
      "Downloaded 346000 rows so far...\n",
      "Downloaded 347000 rows so far...\n",
      "Downloaded 348000 rows so far...\n",
      "Downloaded 349000 rows so far...\n",
      "Downloaded 350000 rows so far...\n",
      "Downloaded 351000 rows so far...\n",
      "Downloaded 352000 rows so far...\n",
      "Downloaded 353000 rows so far...\n",
      "Downloaded 354000 rows so far...\n",
      "Downloaded 355000 rows so far...\n",
      "Downloaded 356000 rows so far...\n",
      "Downloaded 357000 rows so far...\n",
      "Downloaded 358000 rows so far...\n",
      "Downloaded 359000 rows so far...\n",
      "Downloaded 360000 rows so far...\n",
      "Downloaded 361000 rows so far...\n",
      "Downloaded 362000 rows so far...\n",
      "Downloaded 363000 rows so far...\n",
      "Downloaded 364000 rows so far...\n",
      "Downloaded 365000 rows so far...\n",
      "Downloaded 366000 rows so far...\n",
      "Downloaded 367000 rows so far...\n",
      "Downloaded 368000 rows so far...\n",
      "Downloaded 369000 rows so far...\n",
      "Downloaded 370000 rows so far...\n",
      "Downloaded 371000 rows so far...\n",
      "Downloaded 372000 rows so far...\n",
      "Downloaded 373000 rows so far...\n",
      "Downloaded 374000 rows so far...\n",
      "Downloaded 375000 rows so far...\n",
      "Downloaded 376000 rows so far...\n",
      "Downloaded 377000 rows so far...\n",
      "Downloaded 378000 rows so far...\n",
      "Downloaded 379000 rows so far...\n",
      "Downloaded 380000 rows so far...\n",
      "Downloaded 381000 rows so far...\n",
      "Downloaded 382000 rows so far...\n",
      "Downloaded 383000 rows so far...\n",
      "Downloaded 384000 rows so far...\n",
      "Downloaded 385000 rows so far...\n",
      "Downloaded 386000 rows so far...\n",
      "Downloaded 387000 rows so far...\n",
      "Downloaded 388000 rows so far...\n",
      "Downloaded 389000 rows so far...\n",
      "Downloaded 390000 rows so far...\n",
      "Downloaded 391000 rows so far...\n",
      "Downloaded 392000 rows so far...\n",
      "Downloaded 393000 rows so far...\n",
      "Downloaded 394000 rows so far...\n",
      "Downloaded 395000 rows so far...\n",
      "Downloaded 396000 rows so far...\n",
      "Downloaded 397000 rows so far...\n",
      "Downloaded 398000 rows so far...\n",
      "Downloaded 399000 rows so far...\n",
      "Downloaded 400000 rows so far...\n",
      "Downloaded 401000 rows so far...\n",
      "Downloaded 402000 rows so far...\n",
      "Downloaded 403000 rows so far...\n",
      "Downloaded 404000 rows so far...\n",
      "Downloaded 405000 rows so far...\n",
      "Downloaded 406000 rows so far...\n",
      "Downloaded 407000 rows so far...\n",
      "Downloaded 408000 rows so far...\n",
      "Downloaded 409000 rows so far...\n",
      "Downloaded 410000 rows so far...\n",
      "Downloaded 411000 rows so far...\n",
      "Downloaded 412000 rows so far...\n",
      "Downloaded 413000 rows so far...\n",
      "Downloaded 414000 rows so far...\n",
      "Downloaded 415000 rows so far...\n",
      "Downloaded 416000 rows so far...\n",
      "Downloaded 417000 rows so far...\n",
      "Downloaded 418000 rows so far...\n",
      "Downloaded 419000 rows so far...\n",
      "Downloaded 420000 rows so far...\n",
      "Downloaded 421000 rows so far...\n",
      "Downloaded 422000 rows so far...\n",
      "Downloaded 423000 rows so far...\n",
      "Downloaded 424000 rows so far...\n",
      "Downloaded 425000 rows so far...\n",
      "Downloaded 426000 rows so far...\n",
      "Downloaded 427000 rows so far...\n",
      "Downloaded 428000 rows so far...\n",
      "Downloaded 429000 rows so far...\n",
      "Downloaded 430000 rows so far...\n",
      "Downloaded 431000 rows so far...\n",
      "Downloaded 432000 rows so far...\n",
      "Downloaded 433000 rows so far...\n",
      "Downloaded 434000 rows so far...\n",
      "Downloaded 435000 rows so far...\n",
      "Downloaded 436000 rows so far...\n",
      "Downloaded 437000 rows so far...\n",
      "Downloaded 438000 rows so far...\n",
      "Downloaded 439000 rows so far...\n",
      "Downloaded 440000 rows so far...\n",
      "Downloaded 441000 rows so far...\n",
      "Downloaded 442000 rows so far...\n",
      "Downloaded 443000 rows so far...\n",
      "Downloaded 444000 rows so far...\n",
      "Downloaded 445000 rows so far...\n",
      "Downloaded 446000 rows so far...\n",
      "Downloaded 447000 rows so far...\n",
      "Downloaded 448000 rows so far...\n",
      "Downloaded 449000 rows so far...\n",
      "Downloaded 450000 rows so far...\n",
      "Downloaded 451000 rows so far...\n",
      "Downloaded 452000 rows so far...\n",
      "Downloaded 453000 rows so far...\n",
      "Downloaded 454000 rows so far...\n",
      "Downloaded 455000 rows so far...\n",
      "Downloaded 456000 rows so far...\n",
      "Downloaded 457000 rows so far...\n",
      "Downloaded 458000 rows so far...\n",
      "Downloaded 459000 rows so far...\n",
      "Downloaded 460000 rows so far...\n",
      "Downloaded 461000 rows so far...\n",
      "Downloaded 462000 rows so far...\n",
      "Downloaded 463000 rows so far...\n",
      "Downloaded 464000 rows so far...\n",
      "Downloaded 465000 rows so far...\n",
      "Downloaded 466000 rows so far...\n",
      "Downloaded 467000 rows so far...\n",
      "Downloaded 468000 rows so far...\n",
      "Downloaded 469000 rows so far...\n",
      "Downloaded 470000 rows so far...\n",
      "Downloaded 471000 rows so far...\n",
      "Downloaded 472000 rows so far...\n",
      "Downloaded 473000 rows so far...\n",
      "Downloaded 474000 rows so far...\n",
      "Downloaded 475000 rows so far...\n",
      "Downloaded 476000 rows so far...\n",
      "Downloaded 477000 rows so far...\n",
      "Downloaded 478000 rows so far...\n",
      "Downloaded 479000 rows so far...\n",
      "Downloaded 480000 rows so far...\n",
      "Downloaded 481000 rows so far...\n",
      "Downloaded 482000 rows so far...\n",
      "Downloaded 483000 rows so far...\n",
      "Downloaded 484000 rows so far...\n",
      "Downloaded 485000 rows so far...\n",
      "Downloaded 486000 rows so far...\n",
      "Downloaded 487000 rows so far...\n",
      "Downloaded 488000 rows so far...\n",
      "Downloaded 489000 rows so far...\n",
      "Downloaded 490000 rows so far...\n",
      "Downloaded 491000 rows so far...\n",
      "Downloaded 492000 rows so far...\n",
      "Downloaded 493000 rows so far...\n",
      "Downloaded 494000 rows so far...\n",
      "Downloaded 495000 rows so far...\n",
      "Downloaded 496000 rows so far...\n",
      "Downloaded 497000 rows so far...\n",
      "Downloaded 498000 rows so far...\n",
      "Downloaded 499000 rows so far...\n",
      "Downloaded 500000 rows so far...\n",
      "Downloaded 501000 rows so far...\n",
      "Downloaded 502000 rows so far...\n",
      "Downloaded 503000 rows so far...\n",
      "Downloaded 504000 rows so far...\n",
      "Downloaded 505000 rows so far...\n",
      "Downloaded 506000 rows so far...\n",
      "Downloaded 507000 rows so far...\n",
      "Downloaded 508000 rows so far...\n",
      "Downloaded 509000 rows so far...\n",
      "Downloaded 510000 rows so far...\n",
      "Downloaded 511000 rows so far...\n",
      "Downloaded 512000 rows so far...\n",
      "Downloaded 513000 rows so far...\n",
      "Downloaded 514000 rows so far...\n",
      "Downloaded 515000 rows so far...\n",
      "Downloaded 516000 rows so far...\n",
      "Downloaded 517000 rows so far...\n",
      "Downloaded 518000 rows so far...\n",
      "Downloaded 519000 rows so far...\n",
      "Downloaded 520000 rows so far...\n",
      "Downloaded 521000 rows so far...\n",
      "Downloaded 522000 rows so far...\n",
      "Downloaded 523000 rows so far...\n",
      "Downloaded 524000 rows so far...\n",
      "Downloaded 525000 rows so far...\n",
      "Downloaded 526000 rows so far...\n",
      "Downloaded 527000 rows so far...\n",
      "Downloaded 528000 rows so far...\n",
      "Downloaded 529000 rows so far...\n",
      "Downloaded 530000 rows so far...\n",
      "Downloaded 531000 rows so far...\n",
      "Downloaded 532000 rows so far...\n",
      "Downloaded 533000 rows so far...\n",
      "Downloaded 534000 rows so far...\n",
      "Downloaded 535000 rows so far...\n",
      "Downloaded 536000 rows so far...\n",
      "Downloaded 537000 rows so far...\n",
      "Downloaded 538000 rows so far...\n",
      "Downloaded 539000 rows so far...\n",
      "Downloaded 540000 rows so far...\n",
      "Downloaded 541000 rows so far...\n",
      "Downloaded 542000 rows so far...\n",
      "Downloaded 543000 rows so far...\n",
      "Downloaded 544000 rows so far...\n",
      "Downloaded 545000 rows so far...\n",
      "Downloaded 546000 rows so far...\n",
      "Downloaded 547000 rows so far...\n",
      "Downloaded 548000 rows so far...\n",
      "Downloaded 549000 rows so far...\n",
      "Downloaded 550000 rows so far...\n",
      "Downloaded 551000 rows so far...\n",
      "Downloaded 552000 rows so far...\n",
      "Downloaded 553000 rows so far...\n",
      "Downloaded 554000 rows so far...\n",
      "Downloaded 555000 rows so far...\n",
      "Downloaded 556000 rows so far...\n",
      "Downloaded 557000 rows so far...\n",
      "Downloaded 558000 rows so far...\n",
      "Downloaded 559000 rows so far...\n",
      "Downloaded 560000 rows so far...\n",
      "Downloaded 561000 rows so far...\n",
      "Downloaded 562000 rows so far...\n",
      "Downloaded 563000 rows so far...\n",
      "Downloaded 564000 rows so far...\n",
      "Downloaded 565000 rows so far...\n",
      "Downloaded 566000 rows so far...\n",
      "Downloaded 567000 rows so far...\n",
      "Downloaded 568000 rows so far...\n",
      "Downloaded 569000 rows so far...\n",
      "Downloaded 570000 rows so far...\n",
      "Downloaded 571000 rows so far...\n",
      "Downloaded 572000 rows so far...\n",
      "Downloaded 573000 rows so far...\n",
      "Downloaded 574000 rows so far...\n",
      "Downloaded 575000 rows so far...\n",
      "Downloaded 576000 rows so far...\n",
      "Downloaded 577000 rows so far...\n",
      "Downloaded 578000 rows so far...\n",
      "Downloaded 579000 rows so far...\n",
      "Downloaded 580000 rows so far...\n",
      "Downloaded 581000 rows so far...\n",
      "Downloaded 582000 rows so far...\n",
      "Downloaded 583000 rows so far...\n",
      "Downloaded 584000 rows so far...\n",
      "Downloaded 585000 rows so far...\n",
      "Downloaded 586000 rows so far...\n",
      "Downloaded 587000 rows so far...\n",
      "Downloaded 588000 rows so far...\n",
      "Downloaded 589000 rows so far...\n",
      "Downloaded 590000 rows so far...\n",
      "Downloaded 591000 rows so far...\n",
      "Downloaded 592000 rows so far...\n",
      "Downloaded 593000 rows so far...\n",
      "Downloaded 594000 rows so far...\n",
      "Downloaded 595000 rows so far...\n",
      "Downloaded 596000 rows so far...\n",
      "Downloaded 597000 rows so far...\n",
      "Downloaded 598000 rows so far...\n",
      "Downloaded 599000 rows so far...\n",
      "Downloaded 600000 rows so far...\n",
      "Downloaded 601000 rows so far...\n",
      "Downloaded 602000 rows so far...\n",
      "Downloaded 603000 rows so far...\n",
      "Downloaded 604000 rows so far...\n",
      "Downloaded 605000 rows so far...\n",
      "Downloaded 606000 rows so far...\n",
      "Downloaded 607000 rows so far...\n",
      "Downloaded 608000 rows so far...\n",
      "Downloaded 609000 rows so far...\n",
      "Downloaded 610000 rows so far...\n",
      "Downloaded 611000 rows so far...\n",
      "Downloaded 612000 rows so far...\n",
      "Downloaded 613000 rows so far...\n",
      "Downloaded 614000 rows so far...\n",
      "Downloaded 615000 rows so far...\n",
      "Downloaded 616000 rows so far...\n",
      "Downloaded 617000 rows so far...\n",
      "Downloaded 618000 rows so far...\n",
      "Downloaded 619000 rows so far...\n",
      "Downloaded 620000 rows so far...\n",
      "Downloaded 621000 rows so far...\n",
      "Downloaded 622000 rows so far...\n",
      "Downloaded 623000 rows so far...\n",
      "Downloaded 624000 rows so far...\n",
      "Downloaded 625000 rows so far...\n",
      "Downloaded 626000 rows so far...\n",
      "Downloaded 627000 rows so far...\n",
      "Downloaded 628000 rows so far...\n",
      "Downloaded 629000 rows so far...\n",
      "Downloaded 630000 rows so far...\n",
      "Downloaded 631000 rows so far...\n",
      "Downloaded 632000 rows so far...\n",
      "Downloaded 633000 rows so far...\n",
      "Downloaded 634000 rows so far...\n",
      "Downloaded 635000 rows so far...\n",
      "Downloaded 636000 rows so far...\n",
      "Downloaded 637000 rows so far...\n",
      "Downloaded 638000 rows so far...\n",
      "Downloaded 639000 rows so far...\n",
      "Downloaded 640000 rows so far...\n",
      "Downloaded 641000 rows so far...\n",
      "Downloaded 642000 rows so far...\n",
      "Downloaded 643000 rows so far...\n",
      "Downloaded 644000 rows so far...\n",
      "Downloaded 645000 rows so far...\n",
      "Downloaded 646000 rows so far...\n",
      "Downloaded 647000 rows so far...\n",
      "Downloaded 648000 rows so far...\n",
      "Downloaded 649000 rows so far...\n",
      "Downloaded 650000 rows so far...\n",
      "Downloaded 651000 rows so far...\n",
      "Downloaded 652000 rows so far...\n",
      "Downloaded 653000 rows so far...\n",
      "Downloaded 654000 rows so far...\n",
      "Downloaded 655000 rows so far...\n",
      "Downloaded 656000 rows so far...\n",
      "Downloaded 657000 rows so far...\n",
      "Downloaded 658000 rows so far...\n",
      "Downloaded 659000 rows so far...\n",
      "Downloaded 660000 rows so far...\n",
      "Downloaded 661000 rows so far...\n",
      "Downloaded 662000 rows so far...\n",
      "Downloaded 663000 rows so far...\n",
      "Downloaded 664000 rows so far...\n",
      "Downloaded 665000 rows so far...\n",
      "Downloaded 666000 rows so far...\n",
      "Downloaded 667000 rows so far...\n",
      "Downloaded 668000 rows so far...\n",
      "Downloaded 669000 rows so far...\n",
      "Downloaded 670000 rows so far...\n",
      "Downloaded 671000 rows so far...\n",
      "Downloaded 672000 rows so far...\n",
      "Downloaded 673000 rows so far...\n",
      "Downloaded 674000 rows so far...\n",
      "Downloaded 675000 rows so far...\n",
      "Downloaded 676000 rows so far...\n",
      "Downloaded 677000 rows so far...\n",
      "Downloaded 678000 rows so far...\n",
      "Downloaded 679000 rows so far...\n",
      "Downloaded 680000 rows so far...\n",
      "Downloaded 681000 rows so far...\n",
      "Downloaded 682000 rows so far...\n",
      "Downloaded 683000 rows so far...\n",
      "Downloaded 684000 rows so far...\n",
      "Downloaded 685000 rows so far...\n",
      "Downloaded 686000 rows so far...\n",
      "Downloaded 687000 rows so far...\n",
      "Downloaded 688000 rows so far...\n",
      "Downloaded 689000 rows so far...\n",
      "Downloaded 690000 rows so far...\n",
      "Downloaded 691000 rows so far...\n",
      "Downloaded 692000 rows so far...\n",
      "Downloaded 693000 rows so far...\n",
      "Downloaded 694000 rows so far...\n",
      "Downloaded 695000 rows so far...\n",
      "Downloaded 696000 rows so far...\n",
      "Downloaded 697000 rows so far...\n",
      "Downloaded 698000 rows so far...\n",
      "Downloaded 699000 rows so far...\n",
      "Downloaded 700000 rows so far...\n",
      "Downloaded 701000 rows so far...\n",
      "Downloaded 702000 rows so far...\n",
      "Downloaded 703000 rows so far...\n",
      "Downloaded 704000 rows so far...\n",
      "Downloaded 705000 rows so far...\n",
      "Downloaded 706000 rows so far...\n",
      "Downloaded 707000 rows so far...\n",
      "Downloaded 708000 rows so far...\n",
      "Downloaded 709000 rows so far...\n",
      "Downloaded 710000 rows so far...\n",
      "Downloaded 711000 rows so far...\n",
      "Downloaded 712000 rows so far...\n",
      "Downloaded 713000 rows so far...\n",
      "Downloaded 714000 rows so far...\n",
      "Downloaded 715000 rows so far...\n",
      "Downloaded 716000 rows so far...\n",
      "Downloaded 717000 rows so far...\n",
      "Downloaded 718000 rows so far...\n",
      "Downloaded 719000 rows so far...\n",
      "Downloaded 720000 rows so far...\n",
      "Downloaded 721000 rows so far...\n",
      "Downloaded 722000 rows so far...\n",
      "Downloaded 723000 rows so far...\n",
      "Downloaded 724000 rows so far...\n",
      "Downloaded 725000 rows so far...\n",
      "Downloaded 726000 rows so far...\n",
      "Downloaded 727000 rows so far...\n",
      "Downloaded 728000 rows so far...\n",
      "Downloaded 729000 rows so far...\n",
      "Downloaded 730000 rows so far...\n",
      "Downloaded 731000 rows so far...\n",
      "Downloaded 732000 rows so far...\n",
      "Downloaded 733000 rows so far...\n",
      "Downloaded 734000 rows so far...\n",
      "Downloaded 735000 rows so far...\n",
      "Downloaded 736000 rows so far...\n",
      "Downloaded 737000 rows so far...\n",
      "Downloaded 738000 rows so far...\n",
      "Downloaded 739000 rows so far...\n",
      "Downloaded 740000 rows so far...\n",
      "Downloaded 741000 rows so far...\n",
      "Downloaded 742000 rows so far...\n",
      "Downloaded 743000 rows so far...\n",
      "Downloaded 744000 rows so far...\n",
      "Downloaded 745000 rows so far...\n",
      "Downloaded 746000 rows so far...\n",
      "Downloaded 747000 rows so far...\n",
      "Downloaded 748000 rows so far...\n",
      "Downloaded 749000 rows so far...\n",
      "Downloaded 750000 rows so far...\n",
      "Downloaded 751000 rows so far...\n",
      "Downloaded 752000 rows so far...\n",
      "Downloaded 753000 rows so far...\n",
      "Downloaded 754000 rows so far...\n",
      "Downloaded 755000 rows so far...\n",
      "Downloaded 756000 rows so far...\n",
      "Downloaded 757000 rows so far...\n",
      "Downloaded 758000 rows so far...\n",
      "Downloaded 759000 rows so far...\n",
      "Downloaded 760000 rows so far...\n",
      "Downloaded 761000 rows so far...\n",
      "Downloaded 762000 rows so far...\n",
      "Downloaded 763000 rows so far...\n",
      "Downloaded 764000 rows so far...\n",
      "Downloaded 765000 rows so far...\n",
      "Downloaded 766000 rows so far...\n",
      "Downloaded 767000 rows so far...\n",
      "Downloaded 768000 rows so far...\n",
      "Downloaded 769000 rows so far...\n",
      "Downloaded 770000 rows so far...\n",
      "Downloaded 771000 rows so far...\n",
      "Downloaded 772000 rows so far...\n",
      "Downloaded 773000 rows so far...\n",
      "Downloaded 774000 rows so far...\n",
      "Downloaded 775000 rows so far...\n",
      "Downloaded 776000 rows so far...\n",
      "Downloaded 777000 rows so far...\n",
      "Downloaded 778000 rows so far...\n",
      "Downloaded 779000 rows so far...\n",
      "Downloaded 780000 rows so far...\n",
      "Downloaded 781000 rows so far...\n",
      "Downloaded 782000 rows so far...\n",
      "Downloaded 783000 rows so far...\n",
      "Downloaded 784000 rows so far...\n",
      "Downloaded 785000 rows so far...\n",
      "Downloaded 786000 rows so far...\n",
      "Downloaded 787000 rows so far...\n",
      "Downloaded 788000 rows so far...\n",
      "Downloaded 789000 rows so far...\n",
      "Downloaded 790000 rows so far...\n",
      "Downloaded 791000 rows so far...\n",
      "Downloaded 792000 rows so far...\n",
      "Downloaded 793000 rows so far...\n",
      "Downloaded 794000 rows so far...\n",
      "Downloaded 795000 rows so far...\n",
      "Downloaded 796000 rows so far...\n",
      "Downloaded 797000 rows so far...\n",
      "Downloaded 798000 rows so far...\n",
      "Downloaded 799000 rows so far...\n",
      "Downloaded 800000 rows so far...\n",
      "Downloaded 801000 rows so far...\n",
      "Downloaded 802000 rows so far...\n",
      "Downloaded 803000 rows so far...\n",
      "Downloaded 804000 rows so far...\n",
      "Downloaded 805000 rows so far...\n",
      "Downloaded 806000 rows so far...\n",
      "Downloaded 807000 rows so far...\n",
      "Downloaded 808000 rows so far...\n",
      "Downloaded 809000 rows so far...\n",
      "Downloaded 810000 rows so far...\n",
      "Downloaded 811000 rows so far...\n",
      "Downloaded 812000 rows so far...\n",
      "Downloaded 813000 rows so far...\n",
      "Downloaded 814000 rows so far...\n",
      "Downloaded 815000 rows so far...\n",
      "Downloaded 816000 rows so far...\n",
      "Downloaded 817000 rows so far...\n",
      "Downloaded 818000 rows so far...\n",
      "Downloaded 819000 rows so far...\n",
      "Downloaded 820000 rows so far...\n",
      "Downloaded 821000 rows so far...\n",
      "Downloaded 822000 rows so far...\n",
      "Downloaded 823000 rows so far...\n",
      "Downloaded 824000 rows so far...\n",
      "Downloaded 825000 rows so far...\n",
      "Downloaded 826000 rows so far...\n",
      "Downloaded 827000 rows so far...\n",
      "Downloaded 828000 rows so far...\n",
      "Downloaded 829000 rows so far...\n",
      "Downloaded 830000 rows so far...\n",
      "Downloaded 831000 rows so far...\n",
      "Downloaded 832000 rows so far...\n",
      "Downloaded 833000 rows so far...\n",
      "Downloaded 834000 rows so far...\n",
      "Downloaded 835000 rows so far...\n",
      "Downloaded 836000 rows so far...\n",
      "Downloaded 837000 rows so far...\n",
      "Downloaded 838000 rows so far...\n",
      "Downloaded 839000 rows so far...\n",
      "Downloaded 840000 rows so far...\n",
      "Downloaded 841000 rows so far...\n",
      "Downloaded 842000 rows so far...\n",
      "Downloaded 843000 rows so far...\n",
      "Downloaded 844000 rows so far...\n",
      "Downloaded 845000 rows so far...\n",
      "Downloaded 846000 rows so far...\n",
      "Downloaded 847000 rows so far...\n",
      "Downloaded 848000 rows so far...\n",
      "Downloaded 849000 rows so far...\n",
      "Downloaded 850000 rows so far...\n",
      "Downloaded 851000 rows so far...\n",
      "Downloaded 852000 rows so far...\n",
      "Downloaded 853000 rows so far...\n",
      "Downloaded 854000 rows so far...\n",
      "Downloaded 855000 rows so far...\n",
      "Downloaded 856000 rows so far...\n",
      "Downloaded 857000 rows so far...\n",
      "Downloaded 858000 rows so far...\n",
      "Downloaded 859000 rows so far...\n",
      "Downloaded 860000 rows so far...\n",
      "Downloaded 861000 rows so far...\n",
      "Downloaded 862000 rows so far...\n",
      "Downloaded 863000 rows so far...\n",
      "Downloaded 864000 rows so far...\n",
      "Downloaded 865000 rows so far...\n",
      "Downloaded 866000 rows so far...\n",
      "Downloaded 867000 rows so far...\n",
      "Downloaded 868000 rows so far...\n",
      "Downloaded 869000 rows so far...\n",
      "Downloaded 870000 rows so far...\n",
      "Downloaded 871000 rows so far...\n",
      "Downloaded 872000 rows so far...\n",
      "Downloaded 873000 rows so far...\n",
      "Downloaded 874000 rows so far...\n",
      "Downloaded 875000 rows so far...\n",
      "Downloaded 876000 rows so far...\n",
      "Downloaded 877000 rows so far...\n",
      "Downloaded 878000 rows so far...\n",
      "Downloaded 879000 rows so far...\n",
      "Downloaded 880000 rows so far...\n",
      "Downloaded 881000 rows so far...\n",
      "Downloaded 882000 rows so far...\n",
      "Downloaded 883000 rows so far...\n",
      "Downloaded 884000 rows so far...\n",
      "Downloaded 885000 rows so far...\n",
      "Downloaded 886000 rows so far...\n",
      "Downloaded 887000 rows so far...\n",
      "Downloaded 888000 rows so far...\n",
      "Downloaded 889000 rows so far...\n",
      "Downloaded 890000 rows so far...\n",
      "Downloaded 891000 rows so far...\n",
      "Downloaded 892000 rows so far...\n",
      "Downloaded 893000 rows so far...\n",
      "Downloaded 894000 rows so far...\n",
      "Downloaded 895000 rows so far...\n",
      "Downloaded 896000 rows so far...\n",
      "Downloaded 897000 rows so far...\n",
      "Downloaded 898000 rows so far...\n",
      "Downloaded 899000 rows so far...\n",
      "Downloaded 900000 rows so far...\n",
      "Downloaded 901000 rows so far...\n",
      "Downloaded 902000 rows so far...\n",
      "Downloaded 903000 rows so far...\n",
      "Downloaded 904000 rows so far...\n",
      "Downloaded 905000 rows so far...\n",
      "Downloaded 906000 rows so far...\n",
      "Downloaded 907000 rows so far...\n",
      "Downloaded 908000 rows so far...\n",
      "Downloaded 909000 rows so far...\n",
      "Downloaded 910000 rows so far...\n",
      "Downloaded 911000 rows so far...\n",
      "Downloaded 912000 rows so far...\n",
      "Downloaded 913000 rows so far...\n",
      "Downloaded 914000 rows so far...\n",
      "Downloaded 915000 rows so far...\n",
      "Downloaded 916000 rows so far...\n",
      "Downloaded 917000 rows so far...\n",
      "Downloaded 918000 rows so far...\n",
      "Downloaded 919000 rows so far...\n",
      "Downloaded 920000 rows so far...\n",
      "Downloaded 921000 rows so far...\n",
      "Downloaded 922000 rows so far...\n",
      "Downloaded 923000 rows so far...\n",
      "Downloaded 924000 rows so far...\n",
      "Downloaded 925000 rows so far...\n",
      "Downloaded 926000 rows so far...\n",
      "Downloaded 927000 rows so far...\n",
      "Downloaded 928000 rows so far...\n",
      "Downloaded 929000 rows so far...\n",
      "Downloaded 930000 rows so far...\n",
      "Downloaded 931000 rows so far...\n",
      "Downloaded 932000 rows so far...\n",
      "Downloaded 933000 rows so far...\n",
      "Downloaded 934000 rows so far...\n",
      "Downloaded 935000 rows so far...\n",
      "Downloaded 936000 rows so far...\n",
      "Downloaded 937000 rows so far...\n",
      "Downloaded 938000 rows so far...\n",
      "Downloaded 939000 rows so far...\n",
      "Downloaded 940000 rows so far...\n",
      "Downloaded 941000 rows so far...\n",
      "Downloaded 942000 rows so far...\n",
      "Downloaded 943000 rows so far...\n",
      "Downloaded 944000 rows so far...\n",
      "Downloaded 944616 rows so far...\n",
      "Finished! Total rows pulled: 944616\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bedroom</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Area</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Price</th>\n",
       "      <th>2022 Median Income</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Population</th>\n",
       "      <th>City</th>\n",
       "      <th>AQI%Good</th>\n",
       "      <th>WaterQualityVPV</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>2016 Crime Rate</th>\n",
       "      <th>Cost of Living</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2080</td>\n",
       "      <td>0.25</td>\n",
       "      <td>371900</td>\n",
       "      <td>80750.63</td>\n",
       "      <td>1</td>\n",
       "      <td>57453</td>\n",
       "      <td>lancaster,pa</td>\n",
       "      <td>84.38</td>\n",
       "      <td>6</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.015</td>\n",
       "      <td>80190.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2100</td>\n",
       "      <td>0.23</td>\n",
       "      <td>413095</td>\n",
       "      <td>80750.63</td>\n",
       "      <td>1</td>\n",
       "      <td>57453</td>\n",
       "      <td>lancaster,pa</td>\n",
       "      <td>84.38</td>\n",
       "      <td>6</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.015</td>\n",
       "      <td>80190.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10574</td>\n",
       "      <td>68.39</td>\n",
       "      <td>2500000</td>\n",
       "      <td>80899.52</td>\n",
       "      <td>1</td>\n",
       "      <td>44845</td>\n",
       "      <td>york,pa</td>\n",
       "      <td>84.38</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.018</td>\n",
       "      <td>79446.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1722</td>\n",
       "      <td>0.29</td>\n",
       "      <td>188000</td>\n",
       "      <td>80899.52</td>\n",
       "      <td>1</td>\n",
       "      <td>44845</td>\n",
       "      <td>york,pa</td>\n",
       "      <td>84.38</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.018</td>\n",
       "      <td>79446.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1232</td>\n",
       "      <td>0.28</td>\n",
       "      <td>184900</td>\n",
       "      <td>80899.52</td>\n",
       "      <td>1</td>\n",
       "      <td>44845</td>\n",
       "      <td>york,pa</td>\n",
       "      <td>84.38</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.018</td>\n",
       "      <td>79446.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944611</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1018</td>\n",
       "      <td>0.59</td>\n",
       "      <td>120000</td>\n",
       "      <td>73169.57</td>\n",
       "      <td>2</td>\n",
       "      <td>2302878</td>\n",
       "      <td>houston,tx</td>\n",
       "      <td>75.33</td>\n",
       "      <td>0</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.041</td>\n",
       "      <td>68223.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944612</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1896</td>\n",
       "      <td>0.20</td>\n",
       "      <td>642000</td>\n",
       "      <td>73169.57</td>\n",
       "      <td>2</td>\n",
       "      <td>2302878</td>\n",
       "      <td>houston,tx</td>\n",
       "      <td>75.33</td>\n",
       "      <td>0</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.041</td>\n",
       "      <td>68223.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944613</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2440</td>\n",
       "      <td>0.12</td>\n",
       "      <td>314900</td>\n",
       "      <td>73169.57</td>\n",
       "      <td>2</td>\n",
       "      <td>2302878</td>\n",
       "      <td>houston,tx</td>\n",
       "      <td>75.33</td>\n",
       "      <td>0</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.041</td>\n",
       "      <td>68223.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944614</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2768</td>\n",
       "      <td>0.07</td>\n",
       "      <td>369900</td>\n",
       "      <td>73169.57</td>\n",
       "      <td>2</td>\n",
       "      <td>2302878</td>\n",
       "      <td>houston,tx</td>\n",
       "      <td>75.33</td>\n",
       "      <td>0</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.041</td>\n",
       "      <td>68223.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944615</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2132</td>\n",
       "      <td>0.03</td>\n",
       "      <td>419900</td>\n",
       "      <td>73169.57</td>\n",
       "      <td>2</td>\n",
       "      <td>2302878</td>\n",
       "      <td>houston,tx</td>\n",
       "      <td>75.33</td>\n",
       "      <td>0</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.041</td>\n",
       "      <td>68223.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>944616 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bedroom  Bathroom   Area  LotArea    Price  2022 Median Income  \\\n",
       "0             3       3.0   2080     0.25   371900            80750.63   \n",
       "1             4       3.0   2100     0.23   413095            80750.63   \n",
       "2             4       6.0  10574    68.39  2500000            80899.52   \n",
       "3             3       2.0   1722     0.29   188000            80899.52   \n",
       "4             2       2.0   1232     0.28   184900            80899.52   \n",
       "...         ...       ...    ...      ...      ...                 ...   \n",
       "944611        2       2.0   1018     0.59   120000            73169.57   \n",
       "944612        2       2.0   1896     0.20   642000            73169.57   \n",
       "944613        4       3.0   2440     0.12   314900            73169.57   \n",
       "944614        3       4.0   2768     0.07   369900            73169.57   \n",
       "944615        3       4.0   2132     0.03   419900            73169.57   \n",
       "\n",
       "        Temperature  Population          City  AQI%Good  WaterQualityVPV  \\\n",
       "0                 1       57453  lancaster,pa     84.38                6   \n",
       "1                 1       57453  lancaster,pa     84.38                6   \n",
       "2                 1       44845       york,pa     84.38                1   \n",
       "3                 1       44845       york,pa     84.38                1   \n",
       "4                 1       44845       york,pa     84.38                1   \n",
       "...             ...         ...           ...       ...              ...   \n",
       "944611            2     2302878    houston,tx     75.33                0   \n",
       "944612            2     2302878    houston,tx     75.33                0   \n",
       "944613            2     2302878    houston,tx     75.33                0   \n",
       "944614            2     2302878    houston,tx     75.33                0   \n",
       "944615            2     2302878    houston,tx     75.33                0   \n",
       "\n",
       "        Unemployment  2016 Crime Rate  Cost of Living  \n",
       "0               3.65            0.015        80190.68  \n",
       "1               3.65            0.015        80190.68  \n",
       "2               3.94            0.018        79446.63  \n",
       "3               3.94            0.018        79446.63  \n",
       "4               3.94            0.018        79446.63  \n",
       "...              ...              ...             ...  \n",
       "944611          4.41            0.041        68223.99  \n",
       "944612          4.41            0.041        68223.99  \n",
       "944613          4.41            0.041        68223.99  \n",
       "944614          4.41            0.041        68223.99  \n",
       "944615          4.41            0.041        68223.99  \n",
       "\n",
       "[944616 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from supabase import create_client, Client\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Step 1: Connect to Supabase\n",
    "url = os.getenv(\"SUPABASE_URL\")\n",
    "key = os.getenv(\"SUPABASE_KEY\")\n",
    "supabase: Client = create_client(url, key)\n",
    "\n",
    "# Step 2: Set up variables\n",
    "batch_size = 5000\n",
    "offset = 0\n",
    "all_rows = []\n",
    "total_rows_downloaded = 0\n",
    "\n",
    "columns = ','.join([\n",
    "    'Bedroom', 'Bathroom', 'Area', 'LotArea', 'Price',\n",
    "    '\"2022 Median Income\"', 'Temperature', 'Population',\n",
    "    'City', '\"AQI%Good\"', 'WaterQualityVPV', 'Unemployment',\n",
    "    '\"2016 Crime Rate\"', '\"Cost of Living\"'\n",
    "])\n",
    "\n",
    "# Step 3: Pull batches\n",
    "while True:\n",
    "    response = (\n",
    "        supabase\n",
    "        .table('Housing Data 2')\n",
    "        .select(columns)\n",
    "        .range(offset, offset + batch_size - 1)\n",
    "        .execute()\n",
    "    )\n",
    "    batch = response.data\n",
    "\n",
    "    if not batch:\n",
    "        break\n",
    "\n",
    "    all_rows.extend(batch)\n",
    "    batch_size_real = len(batch)\n",
    "    total_rows_downloaded += batch_size_real\n",
    "    offset += batch_size_real\n",
    "\n",
    "    print(f\"Downloaded {total_rows_downloaded} rows so far...\")   # Real progress\n",
    "\n",
    "# Step 4: Build DataFrame\n",
    "merged_df = pd.DataFrame(all_rows)\n",
    "\n",
    "# Step 5: Save\n",
    "merged_df.to_csv('merged_data.csv', index=False)\n",
    "\n",
    "print(f\"Finished! Total rows pulled: {len(merged_df)}\")\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.5: Storing fresh state of merged_df in merged_df2 so that we can refresh the dataframe after potentially modifying it in accuracy tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df2 = merged_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: CREATING FIRST KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adhnata/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended city: bellefontaine,oh\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Reset dataframe\n",
    "merged_df = merged_df2.copy()\n",
    "\n",
    "# Select features for clustering\n",
    "feature_cols = ['Bedroom', 'Bathroom', 'Area', 'LotArea', 'Price', '2022 Median Income', 'Temperature', 'Population']\n",
    "quality_cols = ['AQI%Good', 'WaterQualityVPV', 'Unemployment', '2016 Crime Rate', 'Cost of Living']\n",
    "# Note: Curious about whether or not we should have Cost of Living be an inputted feature variable or if it should just be something that's generally minimized\n",
    "\n",
    "# Preprocess: scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(merged_df[feature_cols])\n",
    "# X = merged_df[feature_cols].values\n",
    "\n",
    "# Get unique cities and map them\n",
    "cities = merged_df['City'].unique()\n",
    "city_to_index = {city: idx for idx, city in enumerate(cities)}\n",
    "index_to_city = {idx: city for city, idx in city_to_index.items()}\n",
    "\n",
    "# Assign city labels\n",
    "y = merged_df['City'].map(city_to_index)\n",
    "\n",
    "# Reduce dimensions for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "\n",
    "def recommend_city(user_input, visualize=True):\n",
    "    # user_input: includes Bedroom, Bathroom, Area, LotArea, Price, Temperature, 2022 Median Income, Population\n",
    "    temp_mapping = {'Cold': 0, 'Medium': 1, 'Hot': 2}\n",
    "    \n",
    "    user_features = np.array([\n",
    "        user_input['Bedroom'],\n",
    "        user_input['Bathroom'],\n",
    "        user_input['Area'],\n",
    "        user_input['LotArea'],\n",
    "        user_input['Price'],\n",
    "        user_input['2022 Median Income'],\n",
    "        temp_mapping[user_input['Temperature']],  # map temp string to number\n",
    "        user_input['Population']\n",
    "    ]).reshape(1, -1)\n",
    "\n",
    "    user_features_scaled = scaler.transform(user_features)\n",
    "\n",
    "    # Calculate Euclidean distances\n",
    "    distances = np.linalg.norm(X - user_features_scaled, axis=1)\n",
    "\n",
    "    # Find k nearest neighbors\n",
    "    k = 5\n",
    "    top_k_indices = np.argsort(distances)[:k]\n",
    "\n",
    "    # Look up corresponding cities\n",
    "    neighbor_cities = y.iloc[top_k_indices].values\n",
    "\n",
    "    # Tally up most common city\n",
    "    unique, counts = np.unique(neighbor_cities, return_counts=True)\n",
    "    candidate_cities = [index_to_city[idx] for idx in unique]\n",
    "\n",
    "    # Filter original df for these candidates\n",
    "    candidates_df = merged_df[merged_df['City'].isin(candidate_cities)].copy()\n",
    "\n",
    "    # Score candidates based on quality metrics (Increasing or decreasing distance based on QoL features)\n",
    "    candidates_df['QualityScore'] = (\n",
    "        candidates_df['AQI%Good'] + candidates_df['WaterQualityVPV']\n",
    "        - candidates_df['Unemployment'] * 2 - candidates_df['2016 Crime Rate'] * 2\n",
    "        - candidates_df['Cost of Living'] * 1.5\n",
    "    )\n",
    "\n",
    "    # Group by city and take the best average score\n",
    "    city_scores = candidates_df.groupby('City')['QualityScore'].mean()\n",
    "\n",
    "    # Best city\n",
    "    best_city = city_scores.idxmax()\n",
    "\n",
    "    visualize = False\n",
    "    if visualize:\n",
    "        # Visualize\n",
    "        user_2d = pca.transform(user_features_scaled)\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sample_size = 5000\n",
    "        if len(merged_df) > sample_size:\n",
    "            sampled_indices = np.random.choice(len(merged_df), size=sample_size, replace=False)\n",
    "            sampled_df = merged_df.iloc[sampled_indices]\n",
    "            X_2d_sampled = X_2d[sampled_indices]\n",
    "        else:\n",
    "            sampled_df = merged_df\n",
    "            X_2d_sampled = X_2d\n",
    "\n",
    "        for city in sampled_df['City'].unique():\n",
    "            mask = sampled_df['City'] == city\n",
    "            plt.scatter(X_2d_sampled[mask, 0], X_2d_sampled[mask, 1], label=city, alpha=0.5)\n",
    "\n",
    "        plt.scatter(user_2d[0, 0], user_2d[0, 1], color='black', marker='X', s=200, label='User Input')\n",
    "\n",
    "        for idx in top_k_indices:\n",
    "            plt.plot([user_2d[0, 0], X_2d[idx, 0]], [user_2d[0, 1], X_2d[idx, 1]], 'k--', alpha=0.7)\n",
    "\n",
    "        plt.title(f'Recommended City: {best_city}')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return best_city\n",
    "\n",
    "# Example user input\n",
    "user_input = {\n",
    "    'Bedroom': 4,\n",
    "    'Bathroom': 4,\n",
    "    'Area': 1500,\n",
    "    'LotArea': 5000,\n",
    "    'Price': 100000,\n",
    "    '2022 Median Income': 70000,\n",
    "    'Temperature': 'Medium',   # Now passed as text\n",
    "    'Population': 150000     # New: user estimates size of city they want\n",
    "}\n",
    "\n",
    "best_city = recommend_city(user_input, visualize=True)\n",
    "print(f\"Recommended city: {best_city}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adhnata/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended city: colorado springs,co\n"
     ]
    }
   ],
   "source": [
    "user_input = {\n",
    "    'Bedroom': 4,\n",
    "    'Bathroom': 4,\n",
    "    'Area': 1500,\n",
    "    'LotArea': 5000,\n",
    "    'Price': 50000,\n",
    "    '2022 Median Income': 100000,\n",
    "    'Temperature': 'Cold',   # Now passed as text\n",
    "    'Population': 1000000     # New: user estimates size of city they want\n",
    "}\n",
    "\n",
    "best_city = recommend_city(user_input, visualize=True)\n",
    "print(f\"Recommended city: {best_city}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: TESTING ACCURACY\n",
    "\n",
    "Note: This first trial tests the accuracy of the features for each row in the testing data returning the specific city that is actually assigned to them. Since our model does not take in quality of life features as inputted Features, but instead tries to pick a city that generally minimizes or maximizes them (depending on the specific QoL feature) by default, this will return a relatively low accuracy since certain cities will have lower quality of life ratings and so will not be returned by the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled model accuracy (on 500 points): 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data (assuming Temperature is already part of X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "\n",
    "# Important: fix randomness\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sample 500 test points\n",
    "sample_size = 500\n",
    "sample_indices = np.random.choice(len(X_test), size=sample_size, replace=False)\n",
    "\n",
    "X_test_sampled = X_test[sample_indices]        # numpy array indexing\n",
    "y_test_sampled = y_test.iloc[sample_indices]   # pandas Series positional indexing\n",
    "\n",
    "# Recommendation function â€” no temperature penalty needed\n",
    "def recommend_city_from_train(user_features_scaled, X_train, y_train, k=5):\n",
    "    distances = np.linalg.norm(X_train - user_features_scaled, axis=1)\n",
    "    \n",
    "    top_k_indices = np.argsort(distances)[:k]\n",
    "    neighbor_cities = y_train.iloc[top_k_indices].values\n",
    "    unique, counts = np.unique(neighbor_cities, return_counts=True)\n",
    "    best_city_idx = unique[np.argmax(counts)]\n",
    "    return best_city_idx\n",
    "\n",
    "# Evaluate accuracy on the sampled test set\n",
    "correct = 0\n",
    "total = len(X_test_sampled)\n",
    "\n",
    "for i in range(total):\n",
    "    user_features_scaled = X_test_sampled[i].reshape(1, -1)  # numpy indexing\n",
    "    predicted_idx = recommend_city_from_train(user_features_scaled, X_train, y_train)\n",
    "    actual_idx = y_test_sampled.iloc[i]  # pandas indexing\n",
    "\n",
    "    if predicted_idx == actual_idx:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Sampled model accuracy (on {sample_size} points): {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: TESTING ACCURACY WITHOUT SIMPLY MAXIMIZING QUALITY OF LIFE FEATURES\n",
    "\n",
    "Now, we tinker with constructing our model to recieve QoL features as input, so that we can see how good it is at generally predicting data. If this model can return a high accuracy, we know our KNN Algorithm is working properly to at least predict the cities accurately. However, for the final model, we will change it back to maximizing or minimizing certain QoL values because we are not just trying to predict a city but are trying to give the user the best option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure Matching Model Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reset dataframe\n",
    "merged_df = merged_df2.copy()\n",
    "\n",
    "# Step 1: Prepare feature set that includes quality of life features + temperature + population\n",
    "full_feature_cols = ['Bedroom', 'Bathroom', 'Area', 'LotArea', 'Price', '2022 Median Income',\n",
    "                     'AQI%Good', 'WaterQualityVPV', 'Unemployment', '2016 Crime Rate', 'Cost of Living', \n",
    "                     'Temperature', 'Population'] \n",
    "\n",
    "# Preprocess: scale the full features\n",
    "scaler_full = StandardScaler()\n",
    "X_full = scaler_full.fit_transform(merged_df[full_feature_cols])\n",
    "# X_full = merged_df[full_feature_cols].values\n",
    "\n",
    "# Labels stay the same\n",
    "y_full = merged_df['City'].map(city_to_index)\n",
    "\n",
    "# Step 2: Train/test split\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full, y_full, test_size=0.05, random_state=42)\n",
    "\n",
    "# Important: fix randomness\n",
    "np.random.seed(42)\n",
    "\n",
    "# Optional: sample 500 points to keep speed reasonable\n",
    "sample_size = 500\n",
    "sample_indices = np.random.choice(len(X_test_full), size=sample_size, replace=False)\n",
    "X_test_sampled_full = X_test_full[sample_indices]\n",
    "y_test_sampled_full = y_test_full.iloc[sample_indices]\n",
    "\n",
    "# Step 3: Define a pure recommend function\n",
    "def pure_recommend_city(user_features_scaled, X_train, y_train, k=5):\n",
    "    distances = np.linalg.norm(X_train - user_features_scaled, axis=1)\n",
    "\n",
    "    top_k_indices = np.argsort(distances)[:k]\n",
    "    neighbor_cities = y_train.iloc[top_k_indices].values\n",
    "    unique, counts = np.unique(neighbor_cities, return_counts=True)\n",
    "    best_city_idx = unique[np.argmax(counts)]\n",
    "    return best_city_idx\n",
    "\n",
    "# Step 4: Evaluate pure matching accuracy\n",
    "correct = 0\n",
    "total = len(X_test_sampled_full)\n",
    "\n",
    "for i in range(total):\n",
    "    user_features_scaled = X_test_sampled_full[i].reshape(1, -1)\n",
    "    predicted_idx = pure_recommend_city(user_features_scaled, X_train_full, y_train_full)\n",
    "    actual_idx = y_test_sampled_full.iloc[i]\n",
    "\n",
    "    if predicted_idx == actual_idx:\n",
    "        correct += 1\n",
    "\n",
    "pure_accuracy = correct / total\n",
    "print(f\"Pure Matching Model Accuracy: {pure_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5: TUNING MODEL PARAMETERS AND SCALARS TO MAXIMIZE ACCURACY\n",
    "\n",
    "- Now, we try to tune the model for higher accuracy by increasing the weights of important, city-defining features, dropping noisy features, increasing the value of k, and other tweaks\n",
    "\n",
    "- Once we find the modifications that maximize the model's accuracy without QoL optimization, we can re-implement these tweaks into the regular model which DOES maximize QoL Values, as we know that these results will be more accurate to the user's inputs while still maximizing better quality of life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure Matching Tuned Model Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reset dataframe\n",
    "merged_df = merged_df2.copy()\n",
    "\n",
    "# Step 1: Prepare feature set that includes quality of life features + temperature + population\n",
    "full_feature_cols = ['Bedroom', 'Bathroom', 'Area', 'LotArea', 'Price', '2022 Median Income',\n",
    "                     'AQI%Good', 'WaterQualityVPV', 'Unemployment', '2016 Crime Rate', 'Cost of Living', \n",
    "                     'Temperature', 'Population']\n",
    "\n",
    "# merged_df[\"2022 Median Income\"] *= 1\n",
    "# merged_df[\"Cost of Living\"] *= 2.5\n",
    "# merged_df[\"Population\"] *= 2\n",
    "# merged_df[\"Temperature\"] *= 2.5 \n",
    "#merged_df['Bedroom'] *= 1.5\n",
    "#merged_df['Bathroom'] *= 1.5\n",
    "#merged_df['Area'] *= 5\n",
    "# merged_df['LotArea'] *= 1.5\n",
    "\n",
    "# Preprocess: scale the full features\n",
    "scaler_full = StandardScaler()\n",
    "X_full = scaler_full.fit_transform(merged_df[full_feature_cols])\n",
    "# X_full = merged_df[full_feature_cols].values\n",
    "\n",
    "# Weigh features to prioritize more important, impactful ones\n",
    "# feature_weights = np.array([1, 1, 1, 1, 1, 2.5, 1, 1, 1, 1, 2, 3, 2])\n",
    "feature_weights = np.array([1, 1, 1, 1.5, 1, 4, 1, 1, 1, 1, 2.5, 3, 3])\n",
    "\n",
    "\n",
    "# Labels stay the same\n",
    "y_full = merged_df['City'].map(city_to_index)\n",
    "\n",
    "# Step 2: Train/test split\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full, y_full, test_size=0.05, random_state=42)\n",
    "\n",
    "# Important: fix randomness\n",
    "np.random.seed(42)\n",
    "\n",
    "# Optional: sample 500 points to keep speed reasonable\n",
    "sample_size = 500\n",
    "sample_indices = np.random.choice(len(X_test_full), size=sample_size, replace=False)\n",
    "X_test_sampled_full = X_test_full[sample_indices]\n",
    "y_test_sampled_full = y_test_full.iloc[sample_indices]\n",
    "\n",
    "# Step 3: Define a pure recommend function (NO temperature penalty anymore)\n",
    "def pure_recommend_city(user_features_scaled, X_train, y_train, k=5):\n",
    "    weighted_diff = (X_train - user_features_scaled) * feature_weights\n",
    "    distances = np.linalg.norm(weighted_diff, axis=1)\n",
    "\n",
    "    top_k_indices = np.argsort(distances)[:k]\n",
    "    neighbor_cities = y_train.iloc[top_k_indices].values\n",
    "    unique, counts = np.unique(neighbor_cities, return_counts=True)\n",
    "    best_city_idx = unique[np.argmax(counts)]\n",
    "    return best_city_idx\n",
    "\n",
    "# Step 4: Evaluate pure matching accuracy\n",
    "correct = 0\n",
    "total = len(X_test_sampled_full)\n",
    "\n",
    "for i in range(total):\n",
    "    user_features_scaled = X_test_sampled_full[i].reshape(1, -1)\n",
    "    predicted_idx = pure_recommend_city(user_features_scaled, X_train_full, y_train_full)\n",
    "    actual_idx = y_test_sampled_full.iloc[i]\n",
    "\n",
    "    if predicted_idx == actual_idx:\n",
    "        correct += 1\n",
    "\n",
    "pure_accuracy = correct / total\n",
    "print(f\"Pure Matching Tuned Model Accuracy: {pure_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6: RECONSTRUCTING A MORE ACCURATE KNN\n",
    "\n",
    "- Now, we reconstruct the KNN with these modifications to get our final, most accurate KNN which prioritizes Quality of Life values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adhnata/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended city: glen rose,tx\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Reset dataframe\n",
    "merged_df = merged_df2.copy()\n",
    "\n",
    "# Select features for clustering\n",
    "feature_cols = ['Bedroom', 'Bathroom', 'Area', 'LotArea', 'Price', '2022 Median Income', 'Temperature', 'Population']\n",
    "quality_cols = ['AQI%Good', 'WaterQualityVPV', 'Unemployment', '2016 Crime Rate', 'Cost of Living']\n",
    "# Note: Curious about whether or not we should have Cost of Living be an inputted feature variable or if it should just be something that's generally minimized\n",
    "\n",
    "# Preprocess: scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(merged_df[feature_cols])\n",
    "# X = merged_df[feature_cols].values\n",
    "\n",
    "# Weigh features to prioritize more important, impactful ones\n",
    "feature_weights = np.array([1, 1, 1, 1.5, 1, 4, 3, 3])\n",
    "\n",
    "# Get unique cities and map them\n",
    "cities = merged_df['City'].unique()\n",
    "city_to_index = {city: idx for idx, city in enumerate(cities)}\n",
    "index_to_city = {idx: city for city, idx in city_to_index.items()}\n",
    "\n",
    "# Assign city labels\n",
    "y = merged_df['City'].map(city_to_index)\n",
    "\n",
    "# Reduce dimensions for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "\n",
    "def recommend_city(user_input, visualize=True):\n",
    "    # user_input: includes Bedroom, Bathroom, Area, LotArea, Price, Temperature, 2022 Median Income, Population\n",
    "    temp_mapping = {'Cold': 0, 'Medium': 1, 'Hot': 2}\n",
    "    \n",
    "    user_features = np.array([\n",
    "        user_input['Bedroom'],\n",
    "        user_input['Bathroom'],\n",
    "        user_input['Area'],\n",
    "        user_input['LotArea'],\n",
    "        user_input['Price'],\n",
    "        user_input['2022 Median Income'],\n",
    "        temp_mapping[user_input['Temperature']],  # map temp string to number\n",
    "        user_input['Population']\n",
    "    ]).reshape(1, -1)\n",
    "\n",
    "    user_features_scaled = scaler.transform(user_features)\n",
    "\n",
    "    # Calculate Euclidean distances\n",
    "    weighted_diff = (X_train - user_features_scaled) * feature_weights\n",
    "    distances = np.linalg.norm(weighted_diff, axis=1)\n",
    "\n",
    "    # Find k nearest neighbors\n",
    "    k = 5\n",
    "    top_k_indices = np.argsort(distances)[:k]\n",
    "\n",
    "    # Look up corresponding cities\n",
    "    neighbor_cities = y.iloc[top_k_indices].values\n",
    "\n",
    "    # Tally up most common city\n",
    "    unique, counts = np.unique(neighbor_cities, return_counts=True)\n",
    "    candidate_cities = [index_to_city[idx] for idx in unique]\n",
    "\n",
    "    # Filter original df for these candidates\n",
    "    candidates_df = merged_df[merged_df['City'].isin(candidate_cities)].copy()\n",
    "\n",
    "    # Score candidates based on quality metrics (Increasing or decreasing distance based on QoL features)\n",
    "    candidates_df['QualityScore'] = (\n",
    "        candidates_df['AQI%Good'] + candidates_df['WaterQualityVPV']\n",
    "        - candidates_df['Unemployment'] * 2\n",
    "        - candidates_df['2016 Crime Rate'] * 2\n",
    "        - candidates_df['Cost of Living'] * 1.5\n",
    "    )\n",
    "\n",
    "    # Group by city and take the best average score\n",
    "    city_scores = candidates_df.groupby('City')['QualityScore'].mean()\n",
    "\n",
    "    # Best city\n",
    "    best_city = city_scores.idxmax()\n",
    "\n",
    "    visualize = False\n",
    "    if visualize:\n",
    "        # Visualize\n",
    "        user_2d = pca.transform(user_features_scaled)\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sample_size = 5000\n",
    "        if len(merged_df) > sample_size:\n",
    "            sampled_indices = np.random.choice(len(merged_df), size=sample_size, replace=False)\n",
    "            sampled_df = merged_df.iloc[sampled_indices]\n",
    "            X_2d_sampled = X_2d[sampled_indices]\n",
    "        else:\n",
    "            sampled_df = merged_df\n",
    "            X_2d_sampled = X_2d\n",
    "\n",
    "        for city in sampled_df['City'].unique():\n",
    "            mask = sampled_df['City'] == city\n",
    "            plt.scatter(X_2d_sampled[mask, 0], X_2d_sampled[mask, 1], label=city, alpha=0.5)\n",
    "\n",
    "        plt.scatter(user_2d[0, 0], user_2d[0, 1], color='black', marker='X', s=200, label='User Input')\n",
    "\n",
    "        for idx in top_k_indices:\n",
    "            plt.plot([user_2d[0, 0], X_2d[idx, 0]], [user_2d[0, 1], X_2d[idx, 1]], 'k--', alpha=0.7)\n",
    "\n",
    "        plt.title(f'Recommended City: {best_city}')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return best_city\n",
    "\n",
    "# Example user input\n",
    "user_input = {\n",
    "    'Bedroom': 3,\n",
    "    'Bathroom': 2,\n",
    "    'Area': 2500,\n",
    "    'LotArea': 5000,\n",
    "    'Price': 1000000,\n",
    "    '2022 Median Income': 160000,\n",
    "    'Temperature': 'Cold',   # Now passed as text\n",
    "    'Population': 500000     # New: user estimates size of city they want\n",
    "}\n",
    "\n",
    "best_city = recommend_city(user_input, visualize=True)\n",
    "print(f\"Recommended city: {best_city}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 7: CREATING A KNN WHICH CAN WORK FOR MISSING USER INPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Trial: KNN will fill missing features with zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_city(user_input, visualize=True):\n",
    "    temp_mapping = {'Cold': 0, 'Medium': 1, 'Hot': 2}\n",
    "\n",
    "    # Mapping feature names to their corresponding order in feature_cols and feature_weights\n",
    "    feature_to_index = {name: idx for idx, name in enumerate(feature_cols)}\n",
    "\n",
    "    # Start with a dummy full 8-feature array (in original feature order)\n",
    "    user_feature_full = np.zeros(len(feature_cols))\n",
    "\n",
    "    provided_features = []\n",
    "    provided_indices = []\n",
    "\n",
    "    for feature in user_input:\n",
    "        if feature not in feature_to_index:\n",
    "            continue\n",
    "        idx = feature_to_index[feature]\n",
    "        value = user_input[feature]\n",
    "        if feature == 'Temperature':\n",
    "            value = temp_mapping[value]\n",
    "        user_feature_full[idx] = value\n",
    "        provided_features.append(feature)\n",
    "        provided_indices.append(idx)\n",
    "\n",
    "    # Scale the full feature vector (8 features)\n",
    "    user_features_scaled_full = scaler.transform(user_feature_full.reshape(1, -1))\n",
    "\n",
    "    # Select only the provided features after scaling\n",
    "    user_features_scaled = user_features_scaled_full[:, provided_indices]\n",
    "\n",
    "    # Also reduce the full X to match only provided features\n",
    "    X_subset = X[:, provided_indices]\n",
    "\n",
    "    # Adjust feature weights\n",
    "    feature_weights_subset = feature_weights[provided_indices]\n",
    "\n",
    "    # Calculate weighted distances\n",
    "    weighted_diff = (X_subset - user_features_scaled) * feature_weights_subset\n",
    "    distances = np.linalg.norm(weighted_diff, axis=1)\n",
    "\n",
    "    # Find k nearest neighbors\n",
    "    k = 5\n",
    "    top_k_indices = np.argsort(distances)[:k]\n",
    "\n",
    "    # Look up corresponding cities\n",
    "    neighbor_cities = y.iloc[top_k_indices].values\n",
    "\n",
    "    unique, counts = np.unique(neighbor_cities, return_counts=True)\n",
    "    candidate_cities = [index_to_city[idx] for idx in unique]\n",
    "\n",
    "    candidates_df = merged_df[merged_df['City'].isin(candidate_cities)].copy()\n",
    "\n",
    "    # Score candidates\n",
    "    candidates_df['QualityScore'] = (\n",
    "        candidates_df['AQI%Good'] + candidates_df['WaterQualityVPV']\n",
    "        - candidates_df['Unemployment'] * 2\n",
    "        - candidates_df['2016 Crime Rate'] * 2\n",
    "        - candidates_df['Cost of Living'] * 1.5\n",
    "    )\n",
    "\n",
    "    city_scores = candidates_df.groupby('City')['QualityScore'].mean()\n",
    "\n",
    "    best_city = city_scores.idxmax()\n",
    "\n",
    "    visualize = False\n",
    "    if visualize:\n",
    "        user_2d = pca.transform(user_features_scaled_full)  # Now safe to transform full\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sample_size = 5000\n",
    "        if len(merged_df) > sample_size:\n",
    "            sampled_indices = np.random.choice(len(merged_df), size=sample_size, replace=False)\n",
    "            sampled_df = merged_df.iloc[sampled_indices]\n",
    "            X_2d_sampled = X_2d[sampled_indices]\n",
    "        else:\n",
    "            sampled_df = merged_df\n",
    "            X_2d_sampled = X_2d\n",
    "\n",
    "        for city in sampled_df['City'].unique():\n",
    "            mask = sampled_df['City'] == city\n",
    "            plt.scatter(X_2d_sampled[mask, 0], X_2d_sampled[mask, 1], label=city, alpha=0.5)\n",
    "\n",
    "        plt.scatter(user_2d[0, 0], user_2d[0, 1], color='black', marker='X', s=200, label='User Input')\n",
    "\n",
    "        for idx in top_k_indices:\n",
    "            plt.plot([user_2d[0, 0], X_2d[idx, 0]], [user_2d[0, 1], X_2d[idx, 1]], 'k--', alpha=0.7)\n",
    "\n",
    "        plt.title(f'Recommended City: {best_city}')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return best_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adhnata/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended city: minneapolis,mn\n"
     ]
    }
   ],
   "source": [
    "user_input = {\n",
    "    'Bedroom': 4,\n",
    "    'Bathroom': 4,\n",
    "    'Area': 1500,\n",
    "    '2022 Median Income': 100000,\n",
    "    'Temperature': 'Cold',   # Now passed as text\n",
    "    'Population': 1000000     # New: user estimates size of city they want\n",
    "}\n",
    "\n",
    "best_city = recommend_city(user_input, visualize=True)\n",
    "print(f\"Recommended city: {best_city}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Trial: KNN completely ignores missing features and only matches provided columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_city(user_input, visualize=True):\n",
    "    temp_mapping = {'Cold': 0, 'Medium': 1, 'Hot': 2}\n",
    "\n",
    "    # Mapping feature names to their corresponding order\n",
    "    feature_to_index = {name: idx for idx, name in enumerate(feature_cols)}\n",
    "\n",
    "    # Find which features were provided\n",
    "    provided_features = []\n",
    "    user_feature_values = []\n",
    "\n",
    "    for feature in feature_cols:\n",
    "        if feature in user_input:\n",
    "            value = user_input[feature]\n",
    "            if feature == 'Temperature':\n",
    "                value = temp_mapping[value]\n",
    "            user_feature_values.append(value)\n",
    "            provided_features.append(feature)\n",
    "\n",
    "    # Get indices of the provided features\n",
    "    provided_indices = [feature_to_index[feat] for feat in provided_features]\n",
    "\n",
    "    # Build training subset\n",
    "    X_subset = X[:, provided_indices]\n",
    "\n",
    "    # Scale user features manually (without touching missing ones)\n",
    "    # Important: We slice the scaler mean and var for only provided columns\n",
    "    scaler_means = scaler.mean_[provided_indices]\n",
    "    scaler_scales = np.sqrt(scaler.var_[provided_indices])\n",
    "\n",
    "    user_features = np.array(user_feature_values).reshape(1, -1)\n",
    "    user_features_scaled = (user_features - scaler_means) / scaler_scales\n",
    "\n",
    "    # Weighted distance\n",
    "    feature_weights_subset = feature_weights[provided_indices]\n",
    "\n",
    "    weighted_diff = (X_subset - user_features_scaled) * feature_weights_subset\n",
    "    distances = np.linalg.norm(weighted_diff, axis=1)\n",
    "\n",
    "    # Find k nearest neighbors\n",
    "    k = 10\n",
    "    unique_cities = set()\n",
    "    while len(unique_cities) < 5 and k <= len(distances):\n",
    "        top_k_idx = np.argsort(distances)[:k]\n",
    "        unique_cities = set(y.iloc[top_k_idx].map(index_to_city))\n",
    "        k *= 2\n",
    "\n",
    "    candidates_df = merged_df[merged_df['City'].isin(unique_cities)].copy()\n",
    "\n",
    "    # Score candidates\n",
    "    candidates_df['QualityScore'] = (\n",
    "        candidates_df['AQI%Good'] + candidates_df['WaterQualityVPV']\n",
    "        - candidates_df['Unemployment'] * 2\n",
    "        - candidates_df['2016 Crime Rate'] * 2\n",
    "        - candidates_df['Cost of Living'] * 1.5\n",
    "    )\n",
    "\n",
    "    city_scores = candidates_df.groupby('City')['QualityScore'].mean()\n",
    "\n",
    "\n",
    "    top_cities = city_scores.sort_values(ascending=False).head(5)\n",
    "\n",
    "    # Visualization (optional)\n",
    "    visualize = False\n",
    "    if visualize:\n",
    "        # Caution: PCA was trained on full 8 features, not subset\n",
    "        # So visualization here would either be approximate or skipped\n",
    "        pass\n",
    "\n",
    "    return top_cities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended city: City\n",
      "finlayson,mn    -98748.424\n",
      "manitowoc,wi   -101229.313\n",
      "neenah,wi      -105073.261\n",
      "oshkosh,wi     -105073.261\n",
      "sheboygan,wi   -105924.052\n",
      "Name: QualityScore, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "user_input = {\n",
    "    'Temperature': 'Cold',   # Now passed as text\n",
    "    # New: user estimates size of city they want\n",
    "}\n",
    "\n",
    "best_city = recommend_city(user_input, visualize=False)\n",
    "print(f\"Recommended city: {best_city}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
