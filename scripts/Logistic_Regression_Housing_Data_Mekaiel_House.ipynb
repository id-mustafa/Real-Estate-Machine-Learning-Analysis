{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install Packages"
      ],
      "metadata": {
        "id": "hSSh9iaisaHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supabase python-dotenv pandas tensorflow scikit-learn joblib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XtRBySbysWMi",
        "outputId": "810ff49e-9073-44f4-d4fc-45923f0c39fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supabase\n",
            "  Downloading supabase-2.15.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Collecting gotrue<3.0.0,>=2.11.0 (from supabase)\n",
            "  Downloading gotrue-2.12.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx<0.29,>=0.26 in /usr/local/lib/python3.11/dist-packages (from supabase) (0.28.1)\n",
            "Collecting postgrest<1.1,>0.19 (from supabase)\n",
            "  Downloading postgrest-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting realtime<2.5.0,>=2.4.0 (from supabase)\n",
            "  Downloading realtime-2.4.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting storage3<0.12,>=0.10 (from supabase)\n",
            "  Downloading storage3-0.11.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting supafunc<0.10,>=0.9 (from supabase)\n",
            "  Downloading supafunc-0.9.4-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.10 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.11.3)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.10.1)\n",
            "Collecting pytest-mock<4.0.0,>=3.14.0 (from gotrue<3.0.0,>=2.11.0->supabase)\n",
            "  Downloading pytest_mock-3.14.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.14.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Collecting deprecation<3.0.0,>=2.1.0 (from postgrest<1.1,>0.19->supabase)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /usr/local/lib/python3.11/dist-packages (from realtime<2.5.0,>=2.4.0->supabase) (3.11.15)\n",
            "Collecting websockets<15,>=11 (from realtime<2.5.0,>=2.4.0->supabase)\n",
            "  Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Collecting strenum<0.5.0,>=0.4.15 (from supafunc<0.10,>=0.9->supabase)\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.14->realtime<2.5.0,>=2.4.0->supabase) (1.20.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.4.0)\n",
            "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.11/dist-packages (from pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (8.3.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (1.5.0)\n",
            "Downloading supabase-2.15.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading gotrue-2.12.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m908.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading postgrest-1.0.1-py3-none-any.whl (22 kB)\n",
            "Downloading realtime-2.4.2-py3-none-any.whl (22 kB)\n",
            "Downloading storage3-0.11.3-py3-none-any.whl (17 kB)\n",
            "Downloading supafunc-0.9.4-py3-none-any.whl (7.8 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pytest_mock-3.14.0-py3-none-any.whl (9.9 kB)\n",
            "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
            "Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: strenum, websockets, python-dotenv, deprecation, pytest-mock, realtime, supafunc, storage3, postgrest, gotrue, supabase\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "Successfully installed deprecation-2.1.0 gotrue-2.12.0 postgrest-1.0.1 pytest-mock-3.14.0 python-dotenv-1.1.0 realtime-2.4.2 storage3-0.11.3 strenum-0.4.15 supabase-2.15.0 supafunc-0.9.4 websockets-14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bring in data"
      ],
      "metadata": {
        "id": "9pnAwq4ZsxeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['SUPABASE_URL'] = 'https://lgcrogvgnqphznuwdopu.supabase.co'\n",
        "os.environ['SUPABASE_KEY'] = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImxnY3JvZ3ZnbnFwaHpudXdkb3B1Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDQ0MTQwMzcsImV4cCI6MjA1OTk5MDAzN30.2lozGgOq70UbrCm1_7Y1p38WbCqOMTjQ8Cs_ZSvNhSs'"
      ],
      "metadata": {
        "id": "v3HYrpXNs8Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import PsiKit Learn"
      ],
      "metadata": {
        "id": "RhPcDOg54oGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "Rz2Dq4tZ4xOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Database Setup"
      ],
      "metadata": {
        "id": "qIgz1FFwtlJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile db.py\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from supabase import create_client, Client\n",
        "import pandas as pd\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
        "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
        "\n",
        "def get_supabase_client() -> Client:\n",
        "    return create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "\n",
        "def fetch_housing_data() -> pd.DataFrame:\n",
        "    client = get_supabase_client()\n",
        "    # Replace \"House\" with your actual table name if different\n",
        "    response = client.table(\"House\").select(\"*\").execute()\n",
        "    data = response.data  # a list of dictionaries\n",
        "    return pd.DataFrame(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "J0EFFUcjtrU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "028c3834-e3bf-49cc-846f-ac71cfb893b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing db.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Database link"
      ],
      "metadata": {
        "id": "aZp22fF6uaC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile db.py\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from supabase import create_client, Client\n",
        "import pandas as pd\n",
        "\n",
        "# Load environment variables from a .env file or your environment\n",
        "load_dotenv()\n",
        "\n",
        "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
        "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
        "\n",
        "def get_supabase_client() -> Client:\n",
        "    return create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "\n",
        "def fetch_housing_data() -> pd.DataFrame:\n",
        "    client = get_supabase_client()\n",
        "    # Replace \"House\" with your actual table name if needed.\n",
        "    response = client.table(\"House\").select(\"*\").execute()\n",
        "    data = response.data  # a list of dictionaries\n",
        "    return pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "LQUwr_JyucoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f056b4e0-7654-4a03-fc25-a5957f985709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting db.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Script"
      ],
      "metadata": {
        "id": "qICHF1HUtuD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_model.py\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from db import fetch_housing_data\n",
        "import joblib\n",
        "\n",
        "def train_model():\n",
        "    # 1. Fetch data from Supabase.\n",
        "    df = fetch_housing_data()\n",
        "    print(\"Data loaded from Supabase:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # 2. Create a binary target from \"QualityOfLifeTotalScore\".\n",
        "    # Here, a score above the median is set to 1 (high quality) and otherwise 0.\n",
        "    threshold = df['QualityOfLifeTotalScore'].median()\n",
        "    df['target'] = (df['QualityOfLifeTotalScore'] > threshold).astype(int)\n",
        "\n",
        "    # Input feature selection.\n",
        "    input_features = ['ListedPrice', 'MeanIncome', 'Bedroom', 'Bathroom', 'Area', '2022 Population']\n",
        "    target_feature = 'target'\n",
        "\n",
        "    # Impute missing values.\n",
        "    X = df[input_features].fillna(df[input_features].median())\n",
        "    y = df[target_feature]\n",
        "\n",
        "    # 3. Scale the input features.\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # 4. Split the data into training and testing sets.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 5. Build the logistic regression model.\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=(X_train.shape[1],)),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # 6. Compile the model with binary_crossentropy and accuracy as metric.\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 7. Train the model. (Using 10% of training data for validation.)\n",
        "    model.fit(X_train, y_train, epochs=50, validation_split=0.1)\n",
        "\n",
        "    # 8. Evaluate the model.\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    print(\"Test loss:\", loss)\n",
        "    print(\"Test accuracy:\", accuracy)\n",
        "\n",
        "    # 9. Save the model and scaler.\n",
        "    model.save(\"trained_model.h5\")\n",
        "    joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_model()\n"
      ],
      "metadata": {
        "id": "xQ1fNRDXtxFG",
        "outputId": "1be90c8a-3a7d-4dde-8b59-fd2215fb84f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add-on"
      ],
      "metadata": {
        "id": "cNN2QR1GxsLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "bbdq2CSnxuVZ",
        "outputId": "f27eb8ed-15a7-4eb3-b1f4-e34877e2cfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_ue9VMYrqLG",
        "outputId": "9244d2da-ccb4-492c-fbed-27ad17441668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions on Model"
      ],
      "metadata": {
        "id": "_oDdWTFRxbLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prediction.py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from db import fetch_housing_data\n",
        "\n",
        "# Feature lists must match training\n",
        "INPUT_FEATURES = ['ListedPrice', 'MeanIncome', 'Bedroom', 'Bathroom', 'Area', '2022 Population']\n",
        "TARGET_COLUMN = 'QualityOfLifeTotalScore'\n",
        "\n",
        "def get_user_input():\n",
        "    \"\"\"Collects user input, allowing skipping any field.\"\"\"\n",
        "    user_input = {}\n",
        "    prompts = {\n",
        "        \"ListedPrice\":     \"Enter your desired house price (or press Enter to skip): \",\n",
        "        \"MeanIncome\":      \"Enter your income (or press Enter to skip): \",\n",
        "        \"Bedroom\":         \"Enter number of beds (or press Enter to skip): \",\n",
        "        \"Bathroom\":        \"Enter number of baths (or press Enter to skip): \",\n",
        "        \"Area\":            \"Enter square footage (or press Enter to skip): \",\n",
        "        \"2022 Population\": \"Enter desired population (or press Enter to skip): \"\n",
        "    }\n",
        "    for key, prompt in prompts.items():\n",
        "        val = input(prompt)\n",
        "        if val.strip():\n",
        "            user_input[key] = float(val) if key not in (\"Bedroom\",\"Bathroom\") else int(val)\n",
        "    return user_input\n",
        "\n",
        "def predict_house_quality(user_input):\n",
        "    \"\"\"Returns (class, probability).\"\"\"\n",
        "    df = fetch_housing_data()\n",
        "    medians = df[INPUT_FEATURES].median()\n",
        "    vector = [ user_input.get(f, medians[f]) for f in INPUT_FEATURES ]\n",
        "    scaled = scaler.transform([vector])\n",
        "    prob = model.predict(scaled)[0,0]\n",
        "    return int(prob > 0.5), prob\n",
        "\n",
        "def find_top_cities(user_input, df, top_n=5):\n",
        "    \"\"\"Return DataFrame of top_n closest cities with distances.\"\"\"\n",
        "    X = df[INPUT_FEATURES].fillna(df[INPUT_FEATURES].median())\n",
        "    X_scaled = scaler.transform(X)\n",
        "    medians = df[INPUT_FEATURES].median()\n",
        "    user_vec = np.array([ user_input.get(f, medians[f]) for f in INPUT_FEATURES ]).reshape(1, -1)\n",
        "    user_scaled = scaler.transform(user_vec)\n",
        "    distances = np.linalg.norm(X_scaled - user_scaled, axis=1)\n",
        "    df2 = df.copy()\n",
        "    df2['distance'] = distances\n",
        "    top = df2.nsmallest(top_n, 'distance')\n",
        "    return top[['City','distance']]\n",
        "\n",
        "# Load model and scaler once\n",
        "model = tf.keras.models.load_model(\"trained_model.h5\")\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) get input & predict\n",
        "    user_input = get_user_input()\n",
        "    cls, prob = predict_house_quality(user_input)\n",
        "    print(f\"\\nPredicted house quality class: {cls} (P={prob:.2f})\")\n",
        "\n",
        "    # 2) fetch data & find top 5 cities\n",
        "    df = fetch_housing_data()\n",
        "    top_cities = find_top_cities(user_input, df, top_n=5)\n",
        "    print(\"\\nTop 5 matching cities:\")\n",
        "    for city, dist in zip(top_cities['City'], top_cities['distance']):\n",
        "        print(f\"  {city}  (distance = {dist:.1f})\")\n",
        "\n",
        "    # 3) bar chart of distances\n",
        "    plt.bar(top_cities['City'], top_cities['distance'])\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.ylabel('Euclidean distance')\n",
        "    plt.title('Top 5 Closest City Matches')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 4) overall accuracy on full dataset\n",
        "    full = fetch_housing_data()\n",
        "    X_full = full[INPUT_FEATURES].fillna(full[INPUT_FEATURES].median())\n",
        "    y_true = (full[TARGET_COLUMN] > full[TARGET_COLUMN].median()).astype(int)\n",
        "    X_scaled_full = scaler.transform(X_full)\n",
        "    y_pred = (model.predict(X_scaled_full).ravel() > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    print(f\"\\nOverall model accuracy (full data): {acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7oPQav1xhn7",
        "outputId": "1a58539b-c88f-4f25-8cf9-9c8db69e6fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prediction.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find closest match"
      ],
      "metadata": {
        "id": "edo3YCq50_ak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training Protocol"
      ],
      "metadata": {
        "id": "IBZcLKkxa73i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVqpunz2a5Dd",
        "outputId": "12228255-d9eb-4945-e874-3e41a86b28d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-25 11:24:33.604127: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745580273.629450   14677 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745580273.636779   14677 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Data loaded from Supabase:\n",
            "  State            City  ...  QualityOfLifeSafety     id\n",
            "0    sd  sioux falls,sd  ...                   29  82672\n",
            "1    sd  sioux falls,sd  ...                   29  82673\n",
            "2    sd  sioux falls,sd  ...                   29  82674\n",
            "3    sd  sioux falls,sd  ...                   29  82675\n",
            "4    sd  sioux falls,sd  ...                   29  82676\n",
            "\n",
            "[5 rows x 22 columns]\n",
            "2025-04-25 11:24:38.699102: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "Epoch 1/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5557 - loss: 0.8602 - val_accuracy: 0.4375 - val_loss: 1.0204\n",
            "Epoch 2/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5463 - loss: 0.8583 - val_accuracy: 0.4625 - val_loss: 0.9827\n",
            "Epoch 3/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5352 - loss: 0.8807 - val_accuracy: 0.4750 - val_loss: 0.9477\n",
            "Epoch 4/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5619 - loss: 0.8409 - val_accuracy: 0.4750 - val_loss: 0.9145\n",
            "Epoch 5/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5642 - loss: 0.7894 - val_accuracy: 0.4750 - val_loss: 0.8814\n",
            "Epoch 6/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5974 - loss: 0.7456 - val_accuracy: 0.5000 - val_loss: 0.8511\n",
            "Epoch 7/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5800 - loss: 0.7555 - val_accuracy: 0.5250 - val_loss: 0.8209\n",
            "Epoch 8/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6191 - loss: 0.7068 - val_accuracy: 0.5250 - val_loss: 0.7937\n",
            "Epoch 9/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5961 - loss: 0.7155 - val_accuracy: 0.5250 - val_loss: 0.7664\n",
            "Epoch 10/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6223 - loss: 0.6849 - val_accuracy: 0.5375 - val_loss: 0.7418\n",
            "Epoch 11/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6265 - loss: 0.6781 - val_accuracy: 0.5625 - val_loss: 0.7169\n",
            "Epoch 12/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6685 - loss: 0.6583 - val_accuracy: 0.5875 - val_loss: 0.6945\n",
            "Epoch 13/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6955 - loss: 0.6334 - val_accuracy: 0.6000 - val_loss: 0.6743\n",
            "Epoch 14/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7009 - loss: 0.6195 - val_accuracy: 0.6375 - val_loss: 0.6530\n",
            "Epoch 15/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7189 - loss: 0.6077 - val_accuracy: 0.6625 - val_loss: 0.6338\n",
            "Epoch 16/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7382 - loss: 0.5860 - val_accuracy: 0.6625 - val_loss: 0.6159\n",
            "Epoch 17/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7494 - loss: 0.5866 - val_accuracy: 0.6625 - val_loss: 0.5990\n",
            "Epoch 18/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7862 - loss: 0.5530 - val_accuracy: 0.7000 - val_loss: 0.5832\n",
            "Epoch 19/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.5369 - val_accuracy: 0.7250 - val_loss: 0.5685\n",
            "Epoch 20/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8249 - loss: 0.5272 - val_accuracy: 0.7750 - val_loss: 0.5549\n",
            "Epoch 21/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8230 - loss: 0.5369 - val_accuracy: 0.8250 - val_loss: 0.5414\n",
            "Epoch 22/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8360 - loss: 0.5294 - val_accuracy: 0.8375 - val_loss: 0.5290\n",
            "Epoch 23/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8789 - loss: 0.5057 - val_accuracy: 0.8625 - val_loss: 0.5177\n",
            "Epoch 24/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9165 - loss: 0.4907 - val_accuracy: 0.8875 - val_loss: 0.5070\n",
            "Epoch 25/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9209 - loss: 0.4895 - val_accuracy: 0.9000 - val_loss: 0.4961\n",
            "Epoch 26/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9264 - loss: 0.4796 - val_accuracy: 0.9250 - val_loss: 0.4860\n",
            "Epoch 27/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9376 - loss: 0.4740 - val_accuracy: 0.9375 - val_loss: 0.4764\n",
            "Epoch 28/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9666 - loss: 0.4561 - val_accuracy: 0.9625 - val_loss: 0.4673\n",
            "Epoch 29/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9599 - loss: 0.4670 - val_accuracy: 0.9750 - val_loss: 0.4585\n",
            "Epoch 30/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9665 - loss: 0.4452 - val_accuracy: 0.9750 - val_loss: 0.4501\n",
            "Epoch 31/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9687 - loss: 0.4423 - val_accuracy: 0.9750 - val_loss: 0.4419\n",
            "Epoch 32/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9727 - loss: 0.4346 - val_accuracy: 0.9750 - val_loss: 0.4338\n",
            "Epoch 33/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.4248 - val_accuracy: 0.9750 - val_loss: 0.4265\n",
            "Epoch 34/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9785 - loss: 0.4172 - val_accuracy: 0.9750 - val_loss: 0.4188\n",
            "Epoch 35/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9806 - loss: 0.4108 - val_accuracy: 0.9750 - val_loss: 0.4116\n",
            "Epoch 36/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9711 - loss: 0.4107 - val_accuracy: 0.9750 - val_loss: 0.4046\n",
            "Epoch 37/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9732 - loss: 0.4013 - val_accuracy: 0.9875 - val_loss: 0.3980\n",
            "Epoch 38/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9842 - loss: 0.3982 - val_accuracy: 0.9875 - val_loss: 0.3912\n",
            "Epoch 39/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9830 - loss: 0.3884 - val_accuracy: 0.9875 - val_loss: 0.3848\n",
            "Epoch 40/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9937 - loss: 0.3717 - val_accuracy: 0.9875 - val_loss: 0.3789\n",
            "Epoch 41/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9805 - loss: 0.3774 - val_accuracy: 0.9875 - val_loss: 0.3725\n",
            "Epoch 42/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9858 - loss: 0.3660 - val_accuracy: 0.9875 - val_loss: 0.3663\n",
            "Epoch 43/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9823 - loss: 0.3676 - val_accuracy: 1.0000 - val_loss: 0.3604\n",
            "Epoch 44/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9887 - loss: 0.3577 - val_accuracy: 1.0000 - val_loss: 0.3546\n",
            "Epoch 45/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9855 - loss: 0.3545 - val_accuracy: 1.0000 - val_loss: 0.3489\n",
            "Epoch 46/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.3500 - val_accuracy: 1.0000 - val_loss: 0.3435\n",
            "Epoch 47/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9838 - loss: 0.3412 - val_accuracy: 1.0000 - val_loss: 0.3381\n",
            "Epoch 48/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9846 - loss: 0.3405 - val_accuracy: 1.0000 - val_loss: 0.3330\n",
            "Epoch 49/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9803 - loss: 0.3406 - val_accuracy: 1.0000 - val_loss: 0.3279\n",
            "Epoch 50/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.3274 - val_accuracy: 1.0000 - val_loss: 0.3230\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9773 - loss: 0.3398 \n",
            "Test loss: 0.3324655592441559\n",
            "Test accuracy: 0.9850000143051147\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python prediction.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bXQ5c1Tskch",
        "outputId": "3ea768b2-bd6f-42c2-db5b-41215d2e5e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-25 11:25:50.195387: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745580350.234621   16628 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745580350.246446   16628 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-25 11:25:56.377272: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Enter your desired house price (or press Enter to skip): 3000000\n",
            "Enter your income (or press Enter to skip): 200000\n",
            "Enter number of beds (or press Enter to skip): \n",
            "Enter number of baths (or press Enter to skip): \n",
            "Enter square footage (or press Enter to skip): \n",
            "Enter desired population (or press Enter to skip): \n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\n",
            "Predicted house quality class: 0 (P=-5.82)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "\n",
            "Top 5 matching cities:\n",
            "  rochester,mn  (distance = 16.6)\n",
            "  rochester,mn  (distance = 16.7)\n",
            "  rochester,mn  (distance = 16.9)\n",
            "  rochester,mn  (distance = 18.0)\n",
            "  rochester,mn  (distance = 18.1)\n",
            "Figure(640x480)\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/prediction.py\", line 82, in <module>\n",
            "    acc = accuracy_score(y_true, y_pred)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 98, in _check_targets\n",
            "    check_consistent_length(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 475, in check_consistent_length\n",
            "    raise ValueError(\n",
            "ValueError: Found input variables with inconsistent numbers of samples: [1000, 3000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "User Input and Output"
      ],
      "metadata": {
        "id": "H2VLUTZW1FIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from db import fetch_housing_data\n",
        "import matplotlib.pyplot as plt\n",
        "from prediction import predict_house_quality, find_closest_match, scaler\n",
        "\n",
        "# Load the full dataset from Supabase.\n",
        "df = fetch_housing_data()  # Ensure that df is defined.\n",
        "print(\"Data loaded:\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 1. Collect user input.\n",
        "def get_user_input():\n",
        "    \"\"\"Collects user input, allowing for skipping some.\"\"\"\n",
        "    user_input = {}\n",
        "\n",
        "    features = {\n",
        "        \"house_price\": \"Enter your desired house price (or press Enter to skip): \",\n",
        "        \"income\": \"Enter your income (or press Enter to skip): \",\n",
        "        \"beds\": \"Enter number of beds (or press Enter to skip): \",\n",
        "        \"baths\": \"Enter number of baths (or press Enter to skip): \",\n",
        "        \"sq_ft\": \"Enter square footage (or press Enter to skip): \",\n",
        "        \"population\": \"Enter desired population (or press Enter to skip): \"\n",
        "    }\n",
        "\n",
        "    for feature, prompt in features.items():\n",
        "        while True:\n",
        "            value = input(prompt)\n",
        "            if value == \"\":  # Skip if empty input\n",
        "                break\n",
        "            try:\n",
        "                user_input[feature] = float(value) if feature != \"beds\" and feature != \"baths\" else int(value)\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number or press Enter to skip.\")\n",
        "\n",
        "    return user_input\n",
        "\n",
        "\n",
        "user_input = get_user_input()\n",
        "\n",
        "# 2. Get the model prediction.\n",
        "prediction = predict_house_quality(user_input)\n",
        "print(\"Predicted house quality class (0 = low, 1 = high):\", prediction)\n",
        "\n",
        "# 3. Reload the full dataset if needed.\n",
        "df = fetch_housing_data()  # or load from a CSV if applicable.\n",
        "print(\"Full dataset loaded (first 5 rows):\")\n",
        "print(df.head(5))\n",
        "\n",
        "# 4. Find the closest matching record.\n",
        "closest_match = find_closest_match(user_input, df, scaler)\n",
        "\n",
        "# 5. Print out details from the best match.\n",
        "print(\"\\nClosest Matching House Record:\")\n",
        "print(\"State:\", closest_match.get(\"State\", \"N/A\"))\n",
        "print(\"City:\", closest_match.get(\"City\", \"N/A\"))\n",
        "print(\"Listed Price:\", closest_match.get(\"ListedPrice\", \"N/A\"))\n",
        "print(\"Mean Income:\", closest_match.get(\"MeanIncome\", \"N/A\"))\n",
        "print(\"Bedrooms:\", closest_match.get(\"Bedroom\", \"N/A\"))\n",
        "print(\"Bathrooms:\", closest_match.get(\"Bathroom\", \"N/A\"))\n",
        "print(\"Area:\", closest_match.get(\"Area\", \"N/A\"))\n",
        "print(\"2022 Population:\", closest_match.get(\"2022 Population\", \"N/A\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD6g5KIgz5VA",
        "outputId": "18abd8a8-5e74-4b02-ab74-d24bcd7a158d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded:\n",
            "  State      City  Bedroom  Bathroom    Area  ListedPrice Temperature  \\\n",
            "0    ne  omaha,ne      2.0       1.0   968.0        79000      Medium   \n",
            "1    ne  omaha,ne      4.0       3.0  2420.0       250000      Medium   \n",
            "2    ne  omaha,ne      3.0       1.0  1388.0       165000      Medium   \n",
            "3    ne  omaha,ne      NaN       NaN     NaN        15500      Medium   \n",
            "4    ne  omaha,ne      3.0       2.0  1888.0       170000      Medium   \n",
            "\n",
            "   2022 Population  2016 Crime Rate  Unemployment  ...  Cost of Living  \\\n",
            "0           586327            0.035          2.73  ...         81031.3   \n",
            "1           586327            0.035          2.73  ...         81031.3   \n",
            "2           586327            0.035          2.73  ...         81031.3   \n",
            "3           586327            0.035          2.73  ...         81031.3   \n",
            "4           586327            0.035          2.73  ...         81031.3   \n",
            "\n",
            "   AVG C2I  MeanIncome  QualityOfLifeTotalScore  QualityOfLifeQualityOfLife  \\\n",
            "0    93.91       60544                    53.08                          32   \n",
            "1    93.91       60544                    53.08                          32   \n",
            "2    93.91       60544                    53.08                          32   \n",
            "3    93.91       60544                    53.08                          32   \n",
            "4    93.91       60544                    53.08                          32   \n",
            "\n",
            "   QualityOfLifeAffordability  QualityOfLifeEconomy  \\\n",
            "0                          31                    20   \n",
            "1                          31                    20   \n",
            "2                          31                    20   \n",
            "3                          31                    20   \n",
            "4                          31                    20   \n",
            "\n",
            "   QualityOfLifeEducationAndHealth  QualityOfLifeSafety     id  \n",
            "0                               17                   28  83283  \n",
            "1                               17                   28  83284  \n",
            "2                               17                   28  83285  \n",
            "3                               17                   28  83286  \n",
            "4                               17                   28  83287  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "Enter your desired house price (or press Enter to skip): 300000\n",
            "Enter your income (or press Enter to skip): 200000\n",
            "Enter number of beds (or press Enter to skip): \n",
            "Enter number of baths (or press Enter to skip): \n",
            "Enter square footage (or press Enter to skip): \n",
            "Enter desired population (or press Enter to skip): \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted house quality class (0 = low, 1 = high): 1\n",
            "Full dataset loaded (first 5 rows):\n",
            "  State          City  Bedroom  Bathroom    Area  ListedPrice Temperature  \\\n",
            "0    wi  milwaukee,wi      4.0       2.0  2014.0        25000        Cold   \n",
            "1    wi  milwaukee,wi      6.0       2.0  2474.0       289900        Cold   \n",
            "2    wi  milwaukee,wi      3.0       2.0  1530.0       184900        Cold   \n",
            "3    wi  milwaukee,wi      3.0       1.0  1300.0       123500        Cold   \n",
            "4    wi  milwaukee,wi      3.0       2.0  1267.0       179000        Cold   \n",
            "\n",
            "   2022 Population  2016 Crime Rate  Unemployment  ...  Cost of Living  \\\n",
            "0           918661             0.05          3.82  ...         72420.6   \n",
            "1           918661             0.05          3.82  ...         72420.6   \n",
            "2           918661             0.05          3.82  ...         72420.6   \n",
            "3           918661             0.05          3.82  ...         72420.6   \n",
            "4           918661             0.05          3.82  ...         72420.6   \n",
            "\n",
            "   AVG C2I  MeanIncome  QualityOfLifeTotalScore  QualityOfLifeQualityOfLife  \\\n",
            "0    108.5       50053                    57.92                          10   \n",
            "1    108.5       50053                    57.92                          10   \n",
            "2    108.5       50053                    57.92                          10   \n",
            "3    108.5       50053                    57.92                          10   \n",
            "4    108.5       50053                    57.92                          10   \n",
            "\n",
            "   QualityOfLifeAffordability  QualityOfLifeEconomy  \\\n",
            "0                          32                    24   \n",
            "1                          32                    24   \n",
            "2                          32                    24   \n",
            "3                          32                    24   \n",
            "4                          32                    24   \n",
            "\n",
            "   QualityOfLifeEducationAndHealth  QualityOfLifeSafety     id  \n",
            "0                               13                   12  84568  \n",
            "1                               13                   12  84569  \n",
            "2                               13                   12  84570  \n",
            "3                               13                   12  84571  \n",
            "4                               13                   12  84572  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "\n",
            "Closest Matching House Record:\n",
            "State: wi\n",
            "City: madison,wi\n",
            "Listed Price: 330000\n",
            "Mean Income: 66490\n",
            "Bedrooms: 4.0\n",
            "Bathrooms: 2.0\n",
            "Area: 2414.0\n",
            "2022 Population: 568203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Model"
      ],
      "metadata": {
        "id": "Jtd9pPrH6VMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from supabase import create_client, Client\n",
        "\n",
        "def fetch_housing_data() -> pd.DataFrame:\n",
        "    load_dotenv()  # Make sure your environment variables are set\n",
        "    SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
        "    SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
        "    client: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "    response = client.table(\"House\").select(\"*\").execute()\n",
        "    data = response.data\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# Import additional metrics from scikit-learn\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# scripts/train_model.py\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "def train_model():\n",
        "    # 1. Fetch data\n",
        "    df = fetch_housing_data()\n",
        "\n",
        "    # 2. Define features/targets\n",
        "    input_features = ['ListedPrice', 'MeanIncome', 'Bedroom', 'Bathroom', 'Area', '2022 Population']\n",
        "    target_features = ['QualityOfLifeTotalScore', 'Cost of Living', '2016 Crime Rate']\n",
        "\n",
        "    X = df[input_features].fillna(df[input_features].median())\n",
        "    y = df[target_features].fillna(df[target_features].median())\n",
        "\n",
        "    # 3. Scale\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # 4. Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 5. Build model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(len(target_features), input_shape=(X_train.shape[1],))\n",
        "    ])\n",
        "\n",
        "    # Change: Since there is only one Dense layer (output),\n",
        "    # use a single loss function and remove loss_weights\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # 6. Train\n",
        "    model.fit(X_train, y_train, epochs=50, validation_split=0.1)\n",
        "\n",
        "    # 7. Evaluate\n",
        "    loss = model.evaluate(X_test, y_test)\n",
        "    print(\"Test loss:\", loss)\n",
        "\n",
        "    # 8. Save model & scaler if needed\n",
        "    model.save(\"trained_model.h5\")\n",
        "    # Optionally pickle the scaler for predictions\n",
        "    import joblib\n",
        "    joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5033df-7840-468e-edfc-ac4642438cba",
        "id": "UohCPn7e6Snb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2144239104.0000 - val_loss: 2146055424.0000\n",
            "Epoch 2/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2140733696.0000 - val_loss: 2146054400.0000\n",
            "Epoch 3/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2165804544.0000 - val_loss: 2146053120.0000\n",
            "Epoch 4/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2165979648.0000 - val_loss: 2146052096.0000\n",
            "Epoch 5/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2144832384.0000 - val_loss: 2146050688.0000\n",
            "Epoch 6/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2144219648.0000 - val_loss: 2146049664.0000\n",
            "Epoch 7/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2139578880.0000 - val_loss: 2146048384.0000\n",
            "Epoch 8/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2157537792.0000 - val_loss: 2146047232.0000\n",
            "Epoch 9/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2157804288.0000 - val_loss: 2146046208.0000\n",
            "Epoch 10/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2150887168.0000 - val_loss: 2146044672.0000\n",
            "Epoch 11/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2141008256.0000 - val_loss: 2146043904.0000\n",
            "Epoch 12/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2153434112.0000 - val_loss: 2146042624.0000\n",
            "Epoch 13/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2159401472.0000 - val_loss: 2146041472.0000\n",
            "Epoch 14/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2138583680.0000 - val_loss: 2146040192.0000\n",
            "Epoch 15/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2160538880.0000 - val_loss: 2146039040.0000\n",
            "Epoch 16/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2150877952.0000 - val_loss: 2146037760.0000\n",
            "Epoch 17/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2156487936.0000 - val_loss: 2146036480.0000\n",
            "Epoch 18/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2137870720.0000 - val_loss: 2146035328.0000\n",
            "Epoch 19/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2137543296.0000 - val_loss: 2146034304.0000\n",
            "Epoch 20/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2155782144.0000 - val_loss: 2146033280.0000\n",
            "Epoch 21/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2148306688.0000 - val_loss: 2146032000.0000\n",
            "Epoch 22/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2138207104.0000 - val_loss: 2146030848.0000\n",
            "Epoch 23/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2155414528.0000 - val_loss: 2146029568.0000\n",
            "Epoch 24/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2154049024.0000 - val_loss: 2146028288.0000\n",
            "Epoch 25/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2175811584.0000 - val_loss: 2146026880.0000\n",
            "Epoch 26/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2131375360.0000 - val_loss: 2146025856.0000\n",
            "Epoch 27/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2143785600.0000 - val_loss: 2146024704.0000\n",
            "Epoch 28/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2154778368.0000 - val_loss: 2146023680.0000\n",
            "Epoch 29/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2144736896.0000 - val_loss: 2146022400.0000\n",
            "Epoch 30/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 2159033856.0000 - val_loss: 2146021120.0000\n",
            "Epoch 31/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 2150495744.0000 - val_loss: 2146020096.0000\n",
            "Epoch 32/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 2161147136.0000 - val_loss: 2146018688.0000\n",
            "Epoch 33/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2153922560.0000 - val_loss: 2146017664.0000\n",
            "Epoch 34/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2158030848.0000 - val_loss: 2146016512.0000\n",
            "Epoch 35/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2155743232.0000 - val_loss: 2146015232.0000\n",
            "Epoch 36/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2152655616.0000 - val_loss: 2146014208.0000\n",
            "Epoch 37/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2142632448.0000 - val_loss: 2146012800.0000\n",
            "Epoch 38/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2144299776.0000 - val_loss: 2146011776.0000\n",
            "Epoch 39/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2143525760.0000 - val_loss: 2146010496.0000\n",
            "Epoch 40/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2146125824.0000 - val_loss: 2146009344.0000\n",
            "Epoch 41/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2156994304.0000 - val_loss: 2146008064.0000\n",
            "Epoch 42/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2166444544.0000 - val_loss: 2146007040.0000\n",
            "Epoch 43/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2145685248.0000 - val_loss: 2146005632.0000\n",
            "Epoch 44/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2142996096.0000 - val_loss: 2146004608.0000\n",
            "Epoch 45/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2152215040.0000 - val_loss: 2146003584.0000\n",
            "Epoch 46/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2152506624.0000 - val_loss: 2146002304.0000\n",
            "Epoch 47/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2149909504.0000 - val_loss: 2146001280.0000\n",
            "Epoch 48/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2152978432.0000 - val_loss: 2145999872.0000\n",
            "Epoch 49/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2141388160.0000 - val_loss: 2145998848.0000\n",
            "Epoch 50/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2148074752.0000 - val_loss: 2145997568.0000\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2132109824.0000 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 2133832704.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}